{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Load + Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import os\n",
    "\n",
    "train_dataset = datasets.MNIST('../data', train=True, download=True,\n",
    "            transform=transforms.Compose([      \n",
    "                transforms.ToTensor(),           \n",
    "                transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ]))\n",
    "\n",
    "test_dataset = datasets.MNIST('../data', train=False,\n",
    "            transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ]))\n",
    "\n",
    "subset_indices_train = np.load('indices_train.npy')\n",
    "subset_indices_valid = np.load('indices_valid.npy')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=64,\n",
    "    sampler=SubsetRandomSampler(subset_indices_train)\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=64,\n",
    "    sampler=SubsetRandomSampler(subset_indices_valid)\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best MNIST Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/51005 (0%)]\tLoss: 2.330586\n",
      "Train Epoch: 1 [640/51005 (1%)]\tLoss: 1.294745\n",
      "Train Epoch: 1 [1280/51005 (3%)]\tLoss: 0.452469\n",
      "Train Epoch: 1 [1920/51005 (4%)]\tLoss: 0.742207\n",
      "Train Epoch: 1 [2560/51005 (5%)]\tLoss: 0.694120\n",
      "Train Epoch: 1 [3200/51005 (6%)]\tLoss: 0.418613\n",
      "Train Epoch: 1 [3840/51005 (8%)]\tLoss: 0.303415\n",
      "Train Epoch: 1 [4480/51005 (9%)]\tLoss: 0.259456\n",
      "Train Epoch: 1 [5120/51005 (10%)]\tLoss: 0.334129\n",
      "Train Epoch: 1 [5760/51005 (11%)]\tLoss: 0.269938\n",
      "Train Epoch: 1 [6400/51005 (13%)]\tLoss: 0.280978\n",
      "Train Epoch: 1 [7040/51005 (14%)]\tLoss: 0.210111\n",
      "Train Epoch: 1 [7680/51005 (15%)]\tLoss: 0.252804\n",
      "Train Epoch: 1 [8320/51005 (16%)]\tLoss: 0.147011\n",
      "Train Epoch: 1 [8960/51005 (18%)]\tLoss: 0.211296\n",
      "Train Epoch: 1 [9600/51005 (19%)]\tLoss: 0.318120\n",
      "Train Epoch: 1 [10240/51005 (20%)]\tLoss: 0.158818\n",
      "Train Epoch: 1 [10880/51005 (21%)]\tLoss: 0.033134\n",
      "Train Epoch: 1 [11520/51005 (23%)]\tLoss: 0.147375\n",
      "Train Epoch: 1 [12160/51005 (24%)]\tLoss: 0.091047\n",
      "Train Epoch: 1 [12800/51005 (25%)]\tLoss: 0.161043\n",
      "Train Epoch: 1 [13440/51005 (26%)]\tLoss: 0.102664\n",
      "Train Epoch: 1 [14080/51005 (28%)]\tLoss: 0.217921\n",
      "Train Epoch: 1 [14720/51005 (29%)]\tLoss: 0.089566\n",
      "Train Epoch: 1 [15360/51005 (30%)]\tLoss: 0.104593\n",
      "Train Epoch: 1 [16000/51005 (31%)]\tLoss: 0.071774\n",
      "Train Epoch: 1 [16640/51005 (33%)]\tLoss: 0.088841\n",
      "Train Epoch: 1 [17280/51005 (34%)]\tLoss: 0.127237\n",
      "Train Epoch: 1 [17920/51005 (35%)]\tLoss: 0.072449\n",
      "Train Epoch: 1 [18560/51005 (36%)]\tLoss: 0.089549\n",
      "Train Epoch: 1 [19200/51005 (38%)]\tLoss: 0.247679\n",
      "Train Epoch: 1 [19840/51005 (39%)]\tLoss: 0.032455\n",
      "Train Epoch: 1 [20480/51005 (40%)]\tLoss: 0.018247\n",
      "Train Epoch: 1 [21120/51005 (41%)]\tLoss: 0.147168\n",
      "Train Epoch: 1 [21760/51005 (43%)]\tLoss: 0.161078\n",
      "Train Epoch: 1 [22400/51005 (44%)]\tLoss: 0.206887\n",
      "Train Epoch: 1 [23040/51005 (45%)]\tLoss: 0.133085\n",
      "Train Epoch: 1 [23680/51005 (46%)]\tLoss: 0.015675\n",
      "Train Epoch: 1 [24320/51005 (48%)]\tLoss: 0.220836\n",
      "Train Epoch: 1 [24960/51005 (49%)]\tLoss: 0.105367\n",
      "Train Epoch: 1 [25600/51005 (50%)]\tLoss: 0.105145\n",
      "Train Epoch: 1 [26240/51005 (51%)]\tLoss: 0.021302\n",
      "Train Epoch: 1 [26880/51005 (53%)]\tLoss: 0.114220\n",
      "Train Epoch: 1 [27520/51005 (54%)]\tLoss: 0.213787\n",
      "Train Epoch: 1 [28160/51005 (55%)]\tLoss: 0.046211\n",
      "Train Epoch: 1 [28800/51005 (56%)]\tLoss: 0.168876\n",
      "Train Epoch: 1 [29440/51005 (58%)]\tLoss: 0.024765\n",
      "Train Epoch: 1 [30080/51005 (59%)]\tLoss: 0.037966\n",
      "Train Epoch: 1 [30720/51005 (60%)]\tLoss: 0.170475\n",
      "Train Epoch: 1 [31360/51005 (61%)]\tLoss: 0.029803\n",
      "Train Epoch: 1 [32000/51005 (63%)]\tLoss: 0.051534\n",
      "Train Epoch: 1 [32640/51005 (64%)]\tLoss: 0.074286\n",
      "Train Epoch: 1 [33280/51005 (65%)]\tLoss: 0.020484\n",
      "Train Epoch: 1 [33920/51005 (66%)]\tLoss: 0.007247\n",
      "Train Epoch: 1 [34560/51005 (68%)]\tLoss: 0.043623\n",
      "Train Epoch: 1 [35200/51005 (69%)]\tLoss: 0.076015\n",
      "Train Epoch: 1 [35840/51005 (70%)]\tLoss: 0.038809\n",
      "Train Epoch: 1 [36480/51005 (72%)]\tLoss: 0.104806\n",
      "Train Epoch: 1 [37120/51005 (73%)]\tLoss: 0.132879\n",
      "Train Epoch: 1 [37760/51005 (74%)]\tLoss: 0.017461\n",
      "Train Epoch: 1 [38400/51005 (75%)]\tLoss: 0.066232\n",
      "Train Epoch: 1 [39040/51005 (77%)]\tLoss: 0.079682\n",
      "Train Epoch: 1 [39680/51005 (78%)]\tLoss: 0.088384\n",
      "Train Epoch: 1 [40320/51005 (79%)]\tLoss: 0.019921\n",
      "Train Epoch: 1 [40960/51005 (80%)]\tLoss: 0.033831\n",
      "Train Epoch: 1 [41600/51005 (82%)]\tLoss: 0.118428\n",
      "Train Epoch: 1 [42240/51005 (83%)]\tLoss: 0.111020\n",
      "Train Epoch: 1 [42880/51005 (84%)]\tLoss: 0.050073\n",
      "Train Epoch: 1 [43520/51005 (85%)]\tLoss: 0.018357\n",
      "Train Epoch: 1 [44160/51005 (87%)]\tLoss: 0.081162\n",
      "Train Epoch: 1 [44800/51005 (88%)]\tLoss: 0.071979\n",
      "Train Epoch: 1 [45440/51005 (89%)]\tLoss: 0.011605\n",
      "Train Epoch: 1 [46080/51005 (90%)]\tLoss: 0.183409\n",
      "Train Epoch: 1 [46720/51005 (92%)]\tLoss: 0.232597\n",
      "Train Epoch: 1 [47360/51005 (93%)]\tLoss: 0.034145\n",
      "Train Epoch: 1 [48000/51005 (94%)]\tLoss: 0.101176\n",
      "Train Epoch: 1 [48640/51005 (95%)]\tLoss: 0.088067\n",
      "Train Epoch: 1 [49280/51005 (97%)]\tLoss: 0.036508\n",
      "Train Epoch: 1 [49920/51005 (98%)]\tLoss: 0.130339\n",
      "Train Epoch: 1 [50560/51005 (99%)]\tLoss: 0.083185\n",
      "\n",
      "Accuracy: 8843/8995 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/51005 (0%)]\tLoss: 0.038395\n",
      "Train Epoch: 2 [640/51005 (1%)]\tLoss: 0.022513\n",
      "Train Epoch: 2 [1280/51005 (3%)]\tLoss: 0.035048\n",
      "Train Epoch: 2 [1920/51005 (4%)]\tLoss: 0.121571\n",
      "Train Epoch: 2 [2560/51005 (5%)]\tLoss: 0.044811\n",
      "Train Epoch: 2 [3200/51005 (6%)]\tLoss: 0.074834\n",
      "Train Epoch: 2 [3840/51005 (8%)]\tLoss: 0.027122\n",
      "Train Epoch: 2 [4480/51005 (9%)]\tLoss: 0.038395\n",
      "Train Epoch: 2 [5120/51005 (10%)]\tLoss: 0.068101\n",
      "Train Epoch: 2 [5760/51005 (11%)]\tLoss: 0.045742\n",
      "Train Epoch: 2 [6400/51005 (13%)]\tLoss: 0.016484\n",
      "Train Epoch: 2 [7040/51005 (14%)]\tLoss: 0.011140\n",
      "Train Epoch: 2 [7680/51005 (15%)]\tLoss: 0.048250\n",
      "Train Epoch: 2 [8320/51005 (16%)]\tLoss: 0.034849\n",
      "Train Epoch: 2 [8960/51005 (18%)]\tLoss: 0.086498\n",
      "Train Epoch: 2 [9600/51005 (19%)]\tLoss: 0.038304\n",
      "Train Epoch: 2 [10240/51005 (20%)]\tLoss: 0.005321\n",
      "Train Epoch: 2 [10880/51005 (21%)]\tLoss: 0.021640\n",
      "Train Epoch: 2 [11520/51005 (23%)]\tLoss: 0.030353\n",
      "Train Epoch: 2 [12160/51005 (24%)]\tLoss: 0.021917\n",
      "Train Epoch: 2 [12800/51005 (25%)]\tLoss: 0.012388\n",
      "Train Epoch: 2 [13440/51005 (26%)]\tLoss: 0.022240\n",
      "Train Epoch: 2 [14080/51005 (28%)]\tLoss: 0.026473\n",
      "Train Epoch: 2 [14720/51005 (29%)]\tLoss: 0.021450\n",
      "Train Epoch: 2 [15360/51005 (30%)]\tLoss: 0.029879\n",
      "Train Epoch: 2 [16000/51005 (31%)]\tLoss: 0.011249\n",
      "Train Epoch: 2 [16640/51005 (33%)]\tLoss: 0.001601\n",
      "Train Epoch: 2 [17280/51005 (34%)]\tLoss: 0.011700\n",
      "Train Epoch: 2 [17920/51005 (35%)]\tLoss: 0.011136\n",
      "Train Epoch: 2 [18560/51005 (36%)]\tLoss: 0.078914\n",
      "Train Epoch: 2 [19200/51005 (38%)]\tLoss: 0.004675\n",
      "Train Epoch: 2 [19840/51005 (39%)]\tLoss: 0.059609\n",
      "Train Epoch: 2 [20480/51005 (40%)]\tLoss: 0.003236\n",
      "Train Epoch: 2 [21120/51005 (41%)]\tLoss: 0.010470\n",
      "Train Epoch: 2 [21760/51005 (43%)]\tLoss: 0.016104\n",
      "Train Epoch: 2 [22400/51005 (44%)]\tLoss: 0.012692\n",
      "Train Epoch: 2 [23040/51005 (45%)]\tLoss: 0.020814\n",
      "Train Epoch: 2 [23680/51005 (46%)]\tLoss: 0.005813\n",
      "Train Epoch: 2 [24320/51005 (48%)]\tLoss: 0.065879\n",
      "Train Epoch: 2 [24960/51005 (49%)]\tLoss: 0.035555\n",
      "Train Epoch: 2 [25600/51005 (50%)]\tLoss: 0.142304\n",
      "Train Epoch: 2 [26240/51005 (51%)]\tLoss: 0.035231\n",
      "Train Epoch: 2 [26880/51005 (53%)]\tLoss: 0.024835\n",
      "Train Epoch: 2 [27520/51005 (54%)]\tLoss: 0.100386\n",
      "Train Epoch: 2 [28160/51005 (55%)]\tLoss: 0.026086\n",
      "Train Epoch: 2 [28800/51005 (56%)]\tLoss: 0.044571\n",
      "Train Epoch: 2 [29440/51005 (58%)]\tLoss: 0.010307\n",
      "Train Epoch: 2 [30080/51005 (59%)]\tLoss: 0.131181\n",
      "Train Epoch: 2 [30720/51005 (60%)]\tLoss: 0.055327\n",
      "Train Epoch: 2 [31360/51005 (61%)]\tLoss: 0.006430\n",
      "Train Epoch: 2 [32000/51005 (63%)]\tLoss: 0.072425\n",
      "Train Epoch: 2 [32640/51005 (64%)]\tLoss: 0.007161\n",
      "Train Epoch: 2 [33280/51005 (65%)]\tLoss: 0.210699\n",
      "Train Epoch: 2 [33920/51005 (66%)]\tLoss: 0.028966\n",
      "Train Epoch: 2 [34560/51005 (68%)]\tLoss: 0.069110\n",
      "Train Epoch: 2 [35200/51005 (69%)]\tLoss: 0.006996\n",
      "Train Epoch: 2 [35840/51005 (70%)]\tLoss: 0.003219\n",
      "Train Epoch: 2 [36480/51005 (72%)]\tLoss: 0.026464\n",
      "Train Epoch: 2 [37120/51005 (73%)]\tLoss: 0.058310\n",
      "Train Epoch: 2 [37760/51005 (74%)]\tLoss: 0.005322\n",
      "Train Epoch: 2 [38400/51005 (75%)]\tLoss: 0.096834\n",
      "Train Epoch: 2 [39040/51005 (77%)]\tLoss: 0.091804\n",
      "Train Epoch: 2 [39680/51005 (78%)]\tLoss: 0.064383\n",
      "Train Epoch: 2 [40320/51005 (79%)]\tLoss: 0.020725\n",
      "Train Epoch: 2 [40960/51005 (80%)]\tLoss: 0.017824\n",
      "Train Epoch: 2 [41600/51005 (82%)]\tLoss: 0.043076\n",
      "Train Epoch: 2 [42240/51005 (83%)]\tLoss: 0.007008\n",
      "Train Epoch: 2 [42880/51005 (84%)]\tLoss: 0.072725\n",
      "Train Epoch: 2 [43520/51005 (85%)]\tLoss: 0.007714\n",
      "Train Epoch: 2 [44160/51005 (87%)]\tLoss: 0.053218\n",
      "Train Epoch: 2 [44800/51005 (88%)]\tLoss: 0.075234\n",
      "Train Epoch: 2 [45440/51005 (89%)]\tLoss: 0.023363\n",
      "Train Epoch: 2 [46080/51005 (90%)]\tLoss: 0.018265\n",
      "Train Epoch: 2 [46720/51005 (92%)]\tLoss: 0.148935\n",
      "Train Epoch: 2 [47360/51005 (93%)]\tLoss: 0.027292\n",
      "Train Epoch: 2 [48000/51005 (94%)]\tLoss: 0.024703\n",
      "Train Epoch: 2 [48640/51005 (95%)]\tLoss: 0.014653\n",
      "Train Epoch: 2 [49280/51005 (97%)]\tLoss: 0.051220\n",
      "Train Epoch: 2 [49920/51005 (98%)]\tLoss: 0.107818\n",
      "Train Epoch: 2 [50560/51005 (99%)]\tLoss: 0.030184\n",
      "\n",
      "Accuracy: 8917/8995 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/51005 (0%)]\tLoss: 0.005935\n",
      "Train Epoch: 3 [640/51005 (1%)]\tLoss: 0.025232\n",
      "Train Epoch: 3 [1280/51005 (3%)]\tLoss: 0.005097\n",
      "Train Epoch: 3 [1920/51005 (4%)]\tLoss: 0.009037\n",
      "Train Epoch: 3 [2560/51005 (5%)]\tLoss: 0.010266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [3200/51005 (6%)]\tLoss: 0.019945\n",
      "Train Epoch: 3 [3840/51005 (8%)]\tLoss: 0.024774\n",
      "Train Epoch: 3 [4480/51005 (9%)]\tLoss: 0.041310\n",
      "Train Epoch: 3 [5120/51005 (10%)]\tLoss: 0.001540\n",
      "Train Epoch: 3 [5760/51005 (11%)]\tLoss: 0.028086\n",
      "Train Epoch: 3 [6400/51005 (13%)]\tLoss: 0.007728\n",
      "Train Epoch: 3 [7040/51005 (14%)]\tLoss: 0.001873\n",
      "Train Epoch: 3 [7680/51005 (15%)]\tLoss: 0.010203\n",
      "Train Epoch: 3 [8320/51005 (16%)]\tLoss: 0.003846\n",
      "Train Epoch: 3 [8960/51005 (18%)]\tLoss: 0.004809\n",
      "Train Epoch: 3 [9600/51005 (19%)]\tLoss: 0.005231\n",
      "Train Epoch: 3 [10240/51005 (20%)]\tLoss: 0.001579\n",
      "Train Epoch: 3 [10880/51005 (21%)]\tLoss: 0.026181\n",
      "Train Epoch: 3 [11520/51005 (23%)]\tLoss: 0.009485\n",
      "Train Epoch: 3 [12160/51005 (24%)]\tLoss: 0.001929\n",
      "Train Epoch: 3 [12800/51005 (25%)]\tLoss: 0.001364\n",
      "Train Epoch: 3 [13440/51005 (26%)]\tLoss: 0.015186\n",
      "Train Epoch: 3 [14080/51005 (28%)]\tLoss: 0.003831\n",
      "Train Epoch: 3 [14720/51005 (29%)]\tLoss: 0.058473\n",
      "Train Epoch: 3 [15360/51005 (30%)]\tLoss: 0.048917\n",
      "Train Epoch: 3 [16000/51005 (31%)]\tLoss: 0.026625\n",
      "Train Epoch: 3 [16640/51005 (33%)]\tLoss: 0.014149\n",
      "Train Epoch: 3 [17280/51005 (34%)]\tLoss: 0.053968\n",
      "Train Epoch: 3 [17920/51005 (35%)]\tLoss: 0.003750\n",
      "Train Epoch: 3 [18560/51005 (36%)]\tLoss: 0.014355\n",
      "Train Epoch: 3 [19200/51005 (38%)]\tLoss: 0.007363\n",
      "Train Epoch: 3 [19840/51005 (39%)]\tLoss: 0.087471\n",
      "Train Epoch: 3 [20480/51005 (40%)]\tLoss: 0.002140\n",
      "Train Epoch: 3 [21120/51005 (41%)]\tLoss: 0.000567\n",
      "Train Epoch: 3 [21760/51005 (43%)]\tLoss: 0.035959\n",
      "Train Epoch: 3 [22400/51005 (44%)]\tLoss: 0.009070\n",
      "Train Epoch: 3 [23040/51005 (45%)]\tLoss: 0.017347\n",
      "Train Epoch: 3 [23680/51005 (46%)]\tLoss: 0.000852\n",
      "Train Epoch: 3 [24320/51005 (48%)]\tLoss: 0.000564\n",
      "Train Epoch: 3 [24960/51005 (49%)]\tLoss: 0.018393\n",
      "Train Epoch: 3 [25600/51005 (50%)]\tLoss: 0.009693\n",
      "Train Epoch: 3 [26240/51005 (51%)]\tLoss: 0.004736\n",
      "Train Epoch: 3 [26880/51005 (53%)]\tLoss: 0.001731\n",
      "Train Epoch: 3 [27520/51005 (54%)]\tLoss: 0.001224\n",
      "Train Epoch: 3 [28160/51005 (55%)]\tLoss: 0.007747\n",
      "Train Epoch: 3 [28800/51005 (56%)]\tLoss: 0.038562\n",
      "Train Epoch: 3 [29440/51005 (58%)]\tLoss: 0.015274\n",
      "Train Epoch: 3 [30080/51005 (59%)]\tLoss: 0.006484\n",
      "Train Epoch: 3 [30720/51005 (60%)]\tLoss: 0.024514\n",
      "Train Epoch: 3 [31360/51005 (61%)]\tLoss: 0.037019\n",
      "Train Epoch: 3 [32000/51005 (63%)]\tLoss: 0.154246\n",
      "Train Epoch: 3 [32640/51005 (64%)]\tLoss: 0.001281\n",
      "Train Epoch: 3 [33280/51005 (65%)]\tLoss: 0.001746\n",
      "Train Epoch: 3 [33920/51005 (66%)]\tLoss: 0.016310\n",
      "Train Epoch: 3 [34560/51005 (68%)]\tLoss: 0.003195\n",
      "Train Epoch: 3 [35200/51005 (69%)]\tLoss: 0.035884\n",
      "Train Epoch: 3 [35840/51005 (70%)]\tLoss: 0.043243\n",
      "Train Epoch: 3 [36480/51005 (72%)]\tLoss: 0.065297\n",
      "Train Epoch: 3 [37120/51005 (73%)]\tLoss: 0.030126\n",
      "Train Epoch: 3 [37760/51005 (74%)]\tLoss: 0.026838\n",
      "Train Epoch: 3 [38400/51005 (75%)]\tLoss: 0.007518\n",
      "Train Epoch: 3 [39040/51005 (77%)]\tLoss: 0.000983\n",
      "Train Epoch: 3 [39680/51005 (78%)]\tLoss: 0.001580\n",
      "Train Epoch: 3 [40320/51005 (79%)]\tLoss: 0.056192\n",
      "Train Epoch: 3 [40960/51005 (80%)]\tLoss: 0.042600\n",
      "Train Epoch: 3 [41600/51005 (82%)]\tLoss: 0.143906\n",
      "Train Epoch: 3 [42240/51005 (83%)]\tLoss: 0.002623\n",
      "Train Epoch: 3 [42880/51005 (84%)]\tLoss: 0.040673\n",
      "Train Epoch: 3 [43520/51005 (85%)]\tLoss: 0.015053\n",
      "Train Epoch: 3 [44160/51005 (87%)]\tLoss: 0.099431\n",
      "Train Epoch: 3 [44800/51005 (88%)]\tLoss: 0.075322\n",
      "Train Epoch: 3 [45440/51005 (89%)]\tLoss: 0.027452\n",
      "Train Epoch: 3 [46080/51005 (90%)]\tLoss: 0.063471\n",
      "Train Epoch: 3 [46720/51005 (92%)]\tLoss: 0.068515\n",
      "Train Epoch: 3 [47360/51005 (93%)]\tLoss: 0.037425\n",
      "Train Epoch: 3 [48000/51005 (94%)]\tLoss: 0.045442\n",
      "Train Epoch: 3 [48640/51005 (95%)]\tLoss: 0.179140\n",
      "Train Epoch: 3 [49280/51005 (97%)]\tLoss: 0.004758\n",
      "Train Epoch: 3 [49920/51005 (98%)]\tLoss: 0.058818\n",
      "Train Epoch: 3 [50560/51005 (99%)]\tLoss: 0.007483\n",
      "\n",
      "Accuracy: 8919/8995 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/51005 (0%)]\tLoss: 0.011471\n",
      "Train Epoch: 4 [640/51005 (1%)]\tLoss: 0.010430\n",
      "Train Epoch: 4 [1280/51005 (3%)]\tLoss: 0.004530\n",
      "Train Epoch: 4 [1920/51005 (4%)]\tLoss: 0.022559\n",
      "Train Epoch: 4 [2560/51005 (5%)]\tLoss: 0.010310\n",
      "Train Epoch: 4 [3200/51005 (6%)]\tLoss: 0.060465\n",
      "Train Epoch: 4 [3840/51005 (8%)]\tLoss: 0.016209\n",
      "Train Epoch: 4 [4480/51005 (9%)]\tLoss: 0.033410\n",
      "Train Epoch: 4 [5120/51005 (10%)]\tLoss: 0.001754\n",
      "Train Epoch: 4 [5760/51005 (11%)]\tLoss: 0.012231\n",
      "Train Epoch: 4 [6400/51005 (13%)]\tLoss: 0.000335\n",
      "Train Epoch: 4 [7040/51005 (14%)]\tLoss: 0.000720\n",
      "Train Epoch: 4 [7680/51005 (15%)]\tLoss: 0.023405\n",
      "Train Epoch: 4 [8320/51005 (16%)]\tLoss: 0.003737\n",
      "Train Epoch: 4 [8960/51005 (18%)]\tLoss: 0.000821\n",
      "Train Epoch: 4 [9600/51005 (19%)]\tLoss: 0.000739\n",
      "Train Epoch: 4 [10240/51005 (20%)]\tLoss: 0.100965\n",
      "Train Epoch: 4 [10880/51005 (21%)]\tLoss: 0.019080\n",
      "Train Epoch: 4 [11520/51005 (23%)]\tLoss: 0.106827\n",
      "Train Epoch: 4 [12160/51005 (24%)]\tLoss: 0.007878\n",
      "Train Epoch: 4 [12800/51005 (25%)]\tLoss: 0.001823\n",
      "Train Epoch: 4 [13440/51005 (26%)]\tLoss: 0.016200\n",
      "Train Epoch: 4 [14080/51005 (28%)]\tLoss: 0.003121\n",
      "Train Epoch: 4 [14720/51005 (29%)]\tLoss: 0.130404\n",
      "Train Epoch: 4 [15360/51005 (30%)]\tLoss: 0.031720\n",
      "Train Epoch: 4 [16000/51005 (31%)]\tLoss: 0.035877\n",
      "Train Epoch: 4 [16640/51005 (33%)]\tLoss: 0.010563\n",
      "Train Epoch: 4 [17280/51005 (34%)]\tLoss: 0.042539\n",
      "Train Epoch: 4 [17920/51005 (35%)]\tLoss: 0.018071\n",
      "Train Epoch: 4 [18560/51005 (36%)]\tLoss: 0.014159\n",
      "Train Epoch: 4 [19200/51005 (38%)]\tLoss: 0.002458\n",
      "Train Epoch: 4 [19840/51005 (39%)]\tLoss: 0.004108\n",
      "Train Epoch: 4 [20480/51005 (40%)]\tLoss: 0.012998\n",
      "Train Epoch: 4 [21120/51005 (41%)]\tLoss: 0.003465\n",
      "Train Epoch: 4 [21760/51005 (43%)]\tLoss: 0.079025\n",
      "Train Epoch: 4 [22400/51005 (44%)]\tLoss: 0.005154\n",
      "Train Epoch: 4 [23040/51005 (45%)]\tLoss: 0.028821\n",
      "Train Epoch: 4 [23680/51005 (46%)]\tLoss: 0.001301\n",
      "Train Epoch: 4 [24320/51005 (48%)]\tLoss: 0.007174\n",
      "Train Epoch: 4 [24960/51005 (49%)]\tLoss: 0.002844\n",
      "Train Epoch: 4 [25600/51005 (50%)]\tLoss: 0.049062\n",
      "Train Epoch: 4 [26240/51005 (51%)]\tLoss: 0.004915\n",
      "Train Epoch: 4 [26880/51005 (53%)]\tLoss: 0.001453\n",
      "Train Epoch: 4 [27520/51005 (54%)]\tLoss: 0.009632\n",
      "Train Epoch: 4 [28160/51005 (55%)]\tLoss: 0.010249\n",
      "Train Epoch: 4 [28800/51005 (56%)]\tLoss: 0.006238\n",
      "Train Epoch: 4 [29440/51005 (58%)]\tLoss: 0.010571\n",
      "Train Epoch: 4 [30080/51005 (59%)]\tLoss: 0.010778\n",
      "Train Epoch: 4 [30720/51005 (60%)]\tLoss: 0.008075\n",
      "Train Epoch: 4 [31360/51005 (61%)]\tLoss: 0.002829\n",
      "Train Epoch: 4 [32000/51005 (63%)]\tLoss: 0.094406\n",
      "Train Epoch: 4 [32640/51005 (64%)]\tLoss: 0.003307\n",
      "Train Epoch: 4 [33280/51005 (65%)]\tLoss: 0.004754\n",
      "Train Epoch: 4 [33920/51005 (66%)]\tLoss: 0.004366\n",
      "Train Epoch: 4 [34560/51005 (68%)]\tLoss: 0.003063\n",
      "Train Epoch: 4 [35200/51005 (69%)]\tLoss: 0.001195\n",
      "Train Epoch: 4 [35840/51005 (70%)]\tLoss: 0.013671\n",
      "Train Epoch: 4 [36480/51005 (72%)]\tLoss: 0.166346\n",
      "Train Epoch: 4 [37120/51005 (73%)]\tLoss: 0.009483\n",
      "Train Epoch: 4 [37760/51005 (74%)]\tLoss: 0.048393\n",
      "Train Epoch: 4 [38400/51005 (75%)]\tLoss: 0.005453\n",
      "Train Epoch: 4 [39040/51005 (77%)]\tLoss: 0.004642\n",
      "Train Epoch: 4 [39680/51005 (78%)]\tLoss: 0.006934\n",
      "Train Epoch: 4 [40320/51005 (79%)]\tLoss: 0.001032\n",
      "Train Epoch: 4 [40960/51005 (80%)]\tLoss: 0.037894\n",
      "Train Epoch: 4 [41600/51005 (82%)]\tLoss: 0.007989\n",
      "Train Epoch: 4 [42240/51005 (83%)]\tLoss: 0.035037\n",
      "Train Epoch: 4 [42880/51005 (84%)]\tLoss: 0.015208\n",
      "Train Epoch: 4 [43520/51005 (85%)]\tLoss: 0.015140\n",
      "Train Epoch: 4 [44160/51005 (87%)]\tLoss: 0.005968\n",
      "Train Epoch: 4 [44800/51005 (88%)]\tLoss: 0.018302\n",
      "Train Epoch: 4 [45440/51005 (89%)]\tLoss: 0.003551\n",
      "Train Epoch: 4 [46080/51005 (90%)]\tLoss: 0.056541\n",
      "Train Epoch: 4 [46720/51005 (92%)]\tLoss: 0.030175\n",
      "Train Epoch: 4 [47360/51005 (93%)]\tLoss: 0.016515\n",
      "Train Epoch: 4 [48000/51005 (94%)]\tLoss: 0.000682\n",
      "Train Epoch: 4 [48640/51005 (95%)]\tLoss: 0.008274\n",
      "Train Epoch: 4 [49280/51005 (97%)]\tLoss: 0.035020\n",
      "Train Epoch: 4 [49920/51005 (98%)]\tLoss: 0.091444\n",
      "Train Epoch: 4 [50560/51005 (99%)]\tLoss: 0.002510\n",
      "\n",
      "Accuracy: 8935/8995 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/51005 (0%)]\tLoss: 0.013022\n",
      "Train Epoch: 5 [640/51005 (1%)]\tLoss: 0.006573\n",
      "Train Epoch: 5 [1280/51005 (3%)]\tLoss: 0.001929\n",
      "Train Epoch: 5 [1920/51005 (4%)]\tLoss: 0.084326\n",
      "Train Epoch: 5 [2560/51005 (5%)]\tLoss: 0.101765\n",
      "Train Epoch: 5 [3200/51005 (6%)]\tLoss: 0.002537\n",
      "Train Epoch: 5 [3840/51005 (8%)]\tLoss: 0.001487\n",
      "Train Epoch: 5 [4480/51005 (9%)]\tLoss: 0.012618\n",
      "Train Epoch: 5 [5120/51005 (10%)]\tLoss: 0.001326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [5760/51005 (11%)]\tLoss: 0.002812\n",
      "Train Epoch: 5 [6400/51005 (13%)]\tLoss: 0.098841\n",
      "Train Epoch: 5 [7040/51005 (14%)]\tLoss: 0.020176\n",
      "Train Epoch: 5 [7680/51005 (15%)]\tLoss: 0.013221\n",
      "Train Epoch: 5 [8320/51005 (16%)]\tLoss: 0.001579\n",
      "Train Epoch: 5 [8960/51005 (18%)]\tLoss: 0.008823\n",
      "Train Epoch: 5 [9600/51005 (19%)]\tLoss: 0.007076\n",
      "Train Epoch: 5 [10240/51005 (20%)]\tLoss: 0.001042\n",
      "Train Epoch: 5 [10880/51005 (21%)]\tLoss: 0.002199\n",
      "Train Epoch: 5 [11520/51005 (23%)]\tLoss: 0.007053\n",
      "Train Epoch: 5 [12160/51005 (24%)]\tLoss: 0.007304\n",
      "Train Epoch: 5 [12800/51005 (25%)]\tLoss: 0.030800\n",
      "Train Epoch: 5 [13440/51005 (26%)]\tLoss: 0.018624\n",
      "Train Epoch: 5 [14080/51005 (28%)]\tLoss: 0.000276\n",
      "Train Epoch: 5 [14720/51005 (29%)]\tLoss: 0.001327\n",
      "Train Epoch: 5 [15360/51005 (30%)]\tLoss: 0.104251\n",
      "Train Epoch: 5 [16000/51005 (31%)]\tLoss: 0.009799\n",
      "Train Epoch: 5 [16640/51005 (33%)]\tLoss: 0.038289\n",
      "Train Epoch: 5 [17280/51005 (34%)]\tLoss: 0.012710\n",
      "Train Epoch: 5 [17920/51005 (35%)]\tLoss: 0.000837\n",
      "Train Epoch: 5 [18560/51005 (36%)]\tLoss: 0.007566\n",
      "Train Epoch: 5 [19200/51005 (38%)]\tLoss: 0.046377\n",
      "Train Epoch: 5 [19840/51005 (39%)]\tLoss: 0.001459\n",
      "Train Epoch: 5 [20480/51005 (40%)]\tLoss: 0.027570\n",
      "Train Epoch: 5 [21120/51005 (41%)]\tLoss: 0.002592\n",
      "Train Epoch: 5 [21760/51005 (43%)]\tLoss: 0.005458\n",
      "Train Epoch: 5 [22400/51005 (44%)]\tLoss: 0.037895\n",
      "Train Epoch: 5 [23040/51005 (45%)]\tLoss: 0.001007\n",
      "Train Epoch: 5 [23680/51005 (46%)]\tLoss: 0.024583\n",
      "Train Epoch: 5 [24320/51005 (48%)]\tLoss: 0.002785\n",
      "Train Epoch: 5 [24960/51005 (49%)]\tLoss: 0.000581\n",
      "Train Epoch: 5 [25600/51005 (50%)]\tLoss: 0.010279\n",
      "Train Epoch: 5 [26240/51005 (51%)]\tLoss: 0.000671\n",
      "Train Epoch: 5 [26880/51005 (53%)]\tLoss: 0.043779\n",
      "Train Epoch: 5 [27520/51005 (54%)]\tLoss: 0.001026\n",
      "Train Epoch: 5 [28160/51005 (55%)]\tLoss: 0.002521\n",
      "Train Epoch: 5 [28800/51005 (56%)]\tLoss: 0.010011\n",
      "Train Epoch: 5 [29440/51005 (58%)]\tLoss: 0.015051\n",
      "Train Epoch: 5 [30080/51005 (59%)]\tLoss: 0.023285\n",
      "Train Epoch: 5 [30720/51005 (60%)]\tLoss: 0.001840\n",
      "Train Epoch: 5 [31360/51005 (61%)]\tLoss: 0.036884\n",
      "Train Epoch: 5 [32000/51005 (63%)]\tLoss: 0.001340\n",
      "Train Epoch: 5 [32640/51005 (64%)]\tLoss: 0.009018\n",
      "Train Epoch: 5 [33280/51005 (65%)]\tLoss: 0.008006\n",
      "Train Epoch: 5 [33920/51005 (66%)]\tLoss: 0.000847\n",
      "Train Epoch: 5 [34560/51005 (68%)]\tLoss: 0.019921\n",
      "Train Epoch: 5 [35200/51005 (69%)]\tLoss: 0.002459\n",
      "Train Epoch: 5 [35840/51005 (70%)]\tLoss: 0.004379\n",
      "Train Epoch: 5 [36480/51005 (72%)]\tLoss: 0.003104\n",
      "Train Epoch: 5 [37120/51005 (73%)]\tLoss: 0.001347\n",
      "Train Epoch: 5 [37760/51005 (74%)]\tLoss: 0.009028\n",
      "Train Epoch: 5 [38400/51005 (75%)]\tLoss: 0.011851\n",
      "Train Epoch: 5 [39040/51005 (77%)]\tLoss: 0.044315\n",
      "Train Epoch: 5 [39680/51005 (78%)]\tLoss: 0.008534\n",
      "Train Epoch: 5 [40320/51005 (79%)]\tLoss: 0.000390\n",
      "Train Epoch: 5 [40960/51005 (80%)]\tLoss: 0.008414\n",
      "Train Epoch: 5 [41600/51005 (82%)]\tLoss: 0.005490\n",
      "Train Epoch: 5 [42240/51005 (83%)]\tLoss: 0.019766\n",
      "Train Epoch: 5 [42880/51005 (84%)]\tLoss: 0.001150\n",
      "Train Epoch: 5 [43520/51005 (85%)]\tLoss: 0.051133\n",
      "Train Epoch: 5 [44160/51005 (87%)]\tLoss: 0.000448\n",
      "Train Epoch: 5 [44800/51005 (88%)]\tLoss: 0.053345\n",
      "Train Epoch: 5 [45440/51005 (89%)]\tLoss: 0.001527\n",
      "Train Epoch: 5 [46080/51005 (90%)]\tLoss: 0.000850\n",
      "Train Epoch: 5 [46720/51005 (92%)]\tLoss: 0.000090\n",
      "Train Epoch: 5 [47360/51005 (93%)]\tLoss: 0.005189\n",
      "Train Epoch: 5 [48000/51005 (94%)]\tLoss: 0.072569\n",
      "Train Epoch: 5 [48640/51005 (95%)]\tLoss: 0.021789\n",
      "Train Epoch: 5 [49280/51005 (97%)]\tLoss: 0.022301\n",
      "Train Epoch: 5 [49920/51005 (98%)]\tLoss: 0.000360\n",
      "Train Epoch: 5 [50560/51005 (99%)]\tLoss: 0.000116\n",
      "\n",
      "Accuracy: 8939/8995 (99%)\n",
      "\n",
      "Train Epoch: 6 [0/51005 (0%)]\tLoss: 0.019523\n",
      "Train Epoch: 6 [640/51005 (1%)]\tLoss: 0.002752\n",
      "Train Epoch: 6 [1280/51005 (3%)]\tLoss: 0.114222\n",
      "Train Epoch: 6 [1920/51005 (4%)]\tLoss: 0.011775\n",
      "Train Epoch: 6 [2560/51005 (5%)]\tLoss: 0.006705\n",
      "Train Epoch: 6 [3200/51005 (6%)]\tLoss: 0.000794\n",
      "Train Epoch: 6 [3840/51005 (8%)]\tLoss: 0.001241\n",
      "Train Epoch: 6 [4480/51005 (9%)]\tLoss: 0.008093\n",
      "Train Epoch: 6 [5120/51005 (10%)]\tLoss: 0.011064\n",
      "Train Epoch: 6 [5760/51005 (11%)]\tLoss: 0.000464\n",
      "Train Epoch: 6 [6400/51005 (13%)]\tLoss: 0.000320\n",
      "Train Epoch: 6 [7040/51005 (14%)]\tLoss: 0.098767\n",
      "Train Epoch: 6 [7680/51005 (15%)]\tLoss: 0.012667\n",
      "Train Epoch: 6 [8320/51005 (16%)]\tLoss: 0.005820\n",
      "Train Epoch: 6 [8960/51005 (18%)]\tLoss: 0.000609\n",
      "Train Epoch: 6 [9600/51005 (19%)]\tLoss: 0.008814\n",
      "Train Epoch: 6 [10240/51005 (20%)]\tLoss: 0.004503\n",
      "Train Epoch: 6 [10880/51005 (21%)]\tLoss: 0.149412\n",
      "Train Epoch: 6 [11520/51005 (23%)]\tLoss: 0.000878\n",
      "Train Epoch: 6 [12160/51005 (24%)]\tLoss: 0.057417\n",
      "Train Epoch: 6 [12800/51005 (25%)]\tLoss: 0.013447\n",
      "Train Epoch: 6 [13440/51005 (26%)]\tLoss: 0.007373\n",
      "Train Epoch: 6 [14080/51005 (28%)]\tLoss: 0.015417\n",
      "Train Epoch: 6 [14720/51005 (29%)]\tLoss: 0.000289\n",
      "Train Epoch: 6 [15360/51005 (30%)]\tLoss: 0.001841\n",
      "Train Epoch: 6 [16000/51005 (31%)]\tLoss: 0.002674\n",
      "Train Epoch: 6 [16640/51005 (33%)]\tLoss: 0.002276\n",
      "Train Epoch: 6 [17280/51005 (34%)]\tLoss: 0.002723\n",
      "Train Epoch: 6 [17920/51005 (35%)]\tLoss: 0.007678\n",
      "Train Epoch: 6 [18560/51005 (36%)]\tLoss: 0.001432\n",
      "Train Epoch: 6 [19200/51005 (38%)]\tLoss: 0.029841\n",
      "Train Epoch: 6 [19840/51005 (39%)]\tLoss: 0.001570\n",
      "Train Epoch: 6 [20480/51005 (40%)]\tLoss: 0.106861\n",
      "Train Epoch: 6 [21120/51005 (41%)]\tLoss: 0.000763\n",
      "Train Epoch: 6 [21760/51005 (43%)]\tLoss: 0.012239\n",
      "Train Epoch: 6 [22400/51005 (44%)]\tLoss: 0.157036\n",
      "Train Epoch: 6 [23040/51005 (45%)]\tLoss: 0.011415\n",
      "Train Epoch: 6 [23680/51005 (46%)]\tLoss: 0.036632\n",
      "Train Epoch: 6 [24320/51005 (48%)]\tLoss: 0.013141\n",
      "Train Epoch: 6 [24960/51005 (49%)]\tLoss: 0.051523\n",
      "Train Epoch: 6 [25600/51005 (50%)]\tLoss: 0.000219\n",
      "Train Epoch: 6 [26240/51005 (51%)]\tLoss: 0.002427\n",
      "Train Epoch: 6 [26880/51005 (53%)]\tLoss: 0.001350\n",
      "Train Epoch: 6 [27520/51005 (54%)]\tLoss: 0.000773\n",
      "Train Epoch: 6 [28160/51005 (55%)]\tLoss: 0.000237\n",
      "Train Epoch: 6 [28800/51005 (56%)]\tLoss: 0.011466\n",
      "Train Epoch: 6 [29440/51005 (58%)]\tLoss: 0.008204\n",
      "Train Epoch: 6 [30080/51005 (59%)]\tLoss: 0.001858\n",
      "Train Epoch: 6 [30720/51005 (60%)]\tLoss: 0.001340\n",
      "Train Epoch: 6 [31360/51005 (61%)]\tLoss: 0.026111\n",
      "Train Epoch: 6 [32000/51005 (63%)]\tLoss: 0.002963\n",
      "Train Epoch: 6 [32640/51005 (64%)]\tLoss: 0.040102\n",
      "Train Epoch: 6 [33280/51005 (65%)]\tLoss: 0.041394\n",
      "Train Epoch: 6 [33920/51005 (66%)]\tLoss: 0.035424\n",
      "Train Epoch: 6 [34560/51005 (68%)]\tLoss: 0.007387\n",
      "Train Epoch: 6 [35200/51005 (69%)]\tLoss: 0.001694\n",
      "Train Epoch: 6 [35840/51005 (70%)]\tLoss: 0.041221\n",
      "Train Epoch: 6 [36480/51005 (72%)]\tLoss: 0.069160\n",
      "Train Epoch: 6 [37120/51005 (73%)]\tLoss: 0.003952\n",
      "Train Epoch: 6 [37760/51005 (74%)]\tLoss: 0.001990\n",
      "Train Epoch: 6 [38400/51005 (75%)]\tLoss: 0.000636\n",
      "Train Epoch: 6 [39040/51005 (77%)]\tLoss: 0.002398\n",
      "Train Epoch: 6 [39680/51005 (78%)]\tLoss: 0.080912\n",
      "Train Epoch: 6 [40320/51005 (79%)]\tLoss: 0.016238\n",
      "Train Epoch: 6 [40960/51005 (80%)]\tLoss: 0.005755\n",
      "Train Epoch: 6 [41600/51005 (82%)]\tLoss: 0.002106\n",
      "Train Epoch: 6 [42240/51005 (83%)]\tLoss: 0.015718\n",
      "Train Epoch: 6 [42880/51005 (84%)]\tLoss: 0.035144\n",
      "Train Epoch: 6 [43520/51005 (85%)]\tLoss: 0.003964\n",
      "Train Epoch: 6 [44160/51005 (87%)]\tLoss: 0.002516\n",
      "Train Epoch: 6 [44800/51005 (88%)]\tLoss: 0.002962\n",
      "Train Epoch: 6 [45440/51005 (89%)]\tLoss: 0.012172\n",
      "Train Epoch: 6 [46080/51005 (90%)]\tLoss: 0.002133\n",
      "Train Epoch: 6 [46720/51005 (92%)]\tLoss: 0.030846\n",
      "Train Epoch: 6 [47360/51005 (93%)]\tLoss: 0.000104\n",
      "Train Epoch: 6 [48000/51005 (94%)]\tLoss: 0.009804\n",
      "Train Epoch: 6 [48640/51005 (95%)]\tLoss: 0.010155\n",
      "Train Epoch: 6 [49280/51005 (97%)]\tLoss: 0.040275\n",
      "Train Epoch: 6 [49920/51005 (98%)]\tLoss: 0.004209\n",
      "Train Epoch: 6 [50560/51005 (99%)]\tLoss: 0.000350\n",
      "\n",
      "Accuracy: 8941/8995 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/51005 (0%)]\tLoss: 0.000936\n",
      "Train Epoch: 7 [640/51005 (1%)]\tLoss: 0.005627\n",
      "Train Epoch: 7 [1280/51005 (3%)]\tLoss: 0.020298\n",
      "Train Epoch: 7 [1920/51005 (4%)]\tLoss: 0.000656\n",
      "Train Epoch: 7 [2560/51005 (5%)]\tLoss: 0.038638\n",
      "Train Epoch: 7 [3200/51005 (6%)]\tLoss: 0.003493\n",
      "Train Epoch: 7 [3840/51005 (8%)]\tLoss: 0.012979\n",
      "Train Epoch: 7 [4480/51005 (9%)]\tLoss: 0.002762\n",
      "Train Epoch: 7 [5120/51005 (10%)]\tLoss: 0.001431\n",
      "Train Epoch: 7 [5760/51005 (11%)]\tLoss: 0.021390\n",
      "Train Epoch: 7 [6400/51005 (13%)]\tLoss: 0.004178\n",
      "Train Epoch: 7 [7040/51005 (14%)]\tLoss: 0.004739\n",
      "Train Epoch: 7 [7680/51005 (15%)]\tLoss: 0.001160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [8320/51005 (16%)]\tLoss: 0.004587\n",
      "Train Epoch: 7 [8960/51005 (18%)]\tLoss: 0.018730\n",
      "Train Epoch: 7 [9600/51005 (19%)]\tLoss: 0.002856\n",
      "Train Epoch: 7 [10240/51005 (20%)]\tLoss: 0.002675\n",
      "Train Epoch: 7 [10880/51005 (21%)]\tLoss: 0.016139\n",
      "Train Epoch: 7 [11520/51005 (23%)]\tLoss: 0.001192\n",
      "Train Epoch: 7 [12160/51005 (24%)]\tLoss: 0.002959\n",
      "Train Epoch: 7 [12800/51005 (25%)]\tLoss: 0.001642\n",
      "Train Epoch: 7 [13440/51005 (26%)]\tLoss: 0.029638\n",
      "Train Epoch: 7 [14080/51005 (28%)]\tLoss: 0.003587\n",
      "Train Epoch: 7 [14720/51005 (29%)]\tLoss: 0.015179\n",
      "Train Epoch: 7 [15360/51005 (30%)]\tLoss: 0.039251\n",
      "Train Epoch: 7 [16000/51005 (31%)]\tLoss: 0.005882\n",
      "Train Epoch: 7 [16640/51005 (33%)]\tLoss: 0.001186\n",
      "Train Epoch: 7 [17280/51005 (34%)]\tLoss: 0.001706\n",
      "Train Epoch: 7 [17920/51005 (35%)]\tLoss: 0.013681\n",
      "Train Epoch: 7 [18560/51005 (36%)]\tLoss: 0.068855\n",
      "Train Epoch: 7 [19200/51005 (38%)]\tLoss: 0.021615\n",
      "Train Epoch: 7 [19840/51005 (39%)]\tLoss: 0.004599\n",
      "Train Epoch: 7 [20480/51005 (40%)]\tLoss: 0.024728\n",
      "Train Epoch: 7 [21120/51005 (41%)]\tLoss: 0.008057\n",
      "Train Epoch: 7 [21760/51005 (43%)]\tLoss: 0.000536\n",
      "Train Epoch: 7 [22400/51005 (44%)]\tLoss: 0.008358\n",
      "Train Epoch: 7 [23040/51005 (45%)]\tLoss: 0.064607\n",
      "Train Epoch: 7 [23680/51005 (46%)]\tLoss: 0.002392\n",
      "Train Epoch: 7 [24320/51005 (48%)]\tLoss: 0.011466\n",
      "Train Epoch: 7 [24960/51005 (49%)]\tLoss: 0.007141\n",
      "Train Epoch: 7 [25600/51005 (50%)]\tLoss: 0.003391\n",
      "Train Epoch: 7 [26240/51005 (51%)]\tLoss: 0.002318\n",
      "Train Epoch: 7 [26880/51005 (53%)]\tLoss: 0.114357\n",
      "Train Epoch: 7 [27520/51005 (54%)]\tLoss: 0.001234\n",
      "Train Epoch: 7 [28160/51005 (55%)]\tLoss: 0.000502\n",
      "Train Epoch: 7 [28800/51005 (56%)]\tLoss: 0.000674\n",
      "Train Epoch: 7 [29440/51005 (58%)]\tLoss: 0.003385\n",
      "Train Epoch: 7 [30080/51005 (59%)]\tLoss: 0.000213\n",
      "Train Epoch: 7 [30720/51005 (60%)]\tLoss: 0.018599\n",
      "Train Epoch: 7 [31360/51005 (61%)]\tLoss: 0.019953\n",
      "Train Epoch: 7 [32000/51005 (63%)]\tLoss: 0.001177\n",
      "Train Epoch: 7 [32640/51005 (64%)]\tLoss: 0.013096\n",
      "Train Epoch: 7 [33280/51005 (65%)]\tLoss: 0.004385\n",
      "Train Epoch: 7 [33920/51005 (66%)]\tLoss: 0.002230\n",
      "Train Epoch: 7 [34560/51005 (68%)]\tLoss: 0.003393\n",
      "Train Epoch: 7 [35200/51005 (69%)]\tLoss: 0.338430\n",
      "Train Epoch: 7 [35840/51005 (70%)]\tLoss: 0.001448\n",
      "Train Epoch: 7 [36480/51005 (72%)]\tLoss: 0.025176\n",
      "Train Epoch: 7 [37120/51005 (73%)]\tLoss: 0.017463\n",
      "Train Epoch: 7 [37760/51005 (74%)]\tLoss: 0.009687\n",
      "Train Epoch: 7 [38400/51005 (75%)]\tLoss: 0.001737\n",
      "Train Epoch: 7 [39040/51005 (77%)]\tLoss: 0.010026\n",
      "Train Epoch: 7 [39680/51005 (78%)]\tLoss: 0.000154\n",
      "Train Epoch: 7 [40320/51005 (79%)]\tLoss: 0.010164\n",
      "Train Epoch: 7 [40960/51005 (80%)]\tLoss: 0.008726\n",
      "Train Epoch: 7 [41600/51005 (82%)]\tLoss: 0.000277\n",
      "Train Epoch: 7 [42240/51005 (83%)]\tLoss: 0.001711\n",
      "Train Epoch: 7 [42880/51005 (84%)]\tLoss: 0.003675\n",
      "Train Epoch: 7 [43520/51005 (85%)]\tLoss: 0.002301\n",
      "Train Epoch: 7 [44160/51005 (87%)]\tLoss: 0.003117\n",
      "Train Epoch: 7 [44800/51005 (88%)]\tLoss: 0.001266\n",
      "Train Epoch: 7 [45440/51005 (89%)]\tLoss: 0.000290\n",
      "Train Epoch: 7 [46080/51005 (90%)]\tLoss: 0.004091\n",
      "Train Epoch: 7 [46720/51005 (92%)]\tLoss: 0.010641\n",
      "Train Epoch: 7 [47360/51005 (93%)]\tLoss: 0.004261\n",
      "Train Epoch: 7 [48000/51005 (94%)]\tLoss: 0.009379\n",
      "Train Epoch: 7 [48640/51005 (95%)]\tLoss: 0.016544\n",
      "Train Epoch: 7 [49280/51005 (97%)]\tLoss: 0.001495\n",
      "Train Epoch: 7 [49920/51005 (98%)]\tLoss: 0.002824\n",
      "Train Epoch: 7 [50560/51005 (99%)]\tLoss: 0.082931\n",
      "\n",
      "Accuracy: 8940/8995 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/51005 (0%)]\tLoss: 0.007855\n",
      "Train Epoch: 8 [640/51005 (1%)]\tLoss: 0.003017\n",
      "Train Epoch: 8 [1280/51005 (3%)]\tLoss: 0.007034\n",
      "Train Epoch: 8 [1920/51005 (4%)]\tLoss: 0.001454\n",
      "Train Epoch: 8 [2560/51005 (5%)]\tLoss: 0.000488\n",
      "Train Epoch: 8 [3200/51005 (6%)]\tLoss: 0.002650\n",
      "Train Epoch: 8 [3840/51005 (8%)]\tLoss: 0.035583\n",
      "Train Epoch: 8 [4480/51005 (9%)]\tLoss: 0.009363\n",
      "Train Epoch: 8 [5120/51005 (10%)]\tLoss: 0.000467\n",
      "Train Epoch: 8 [5760/51005 (11%)]\tLoss: 0.051493\n",
      "Train Epoch: 8 [6400/51005 (13%)]\tLoss: 0.003138\n",
      "Train Epoch: 8 [7040/51005 (14%)]\tLoss: 0.005496\n",
      "Train Epoch: 8 [7680/51005 (15%)]\tLoss: 0.001842\n",
      "Train Epoch: 8 [8320/51005 (16%)]\tLoss: 0.001187\n",
      "Train Epoch: 8 [8960/51005 (18%)]\tLoss: 0.001042\n",
      "Train Epoch: 8 [9600/51005 (19%)]\tLoss: 0.003868\n",
      "Train Epoch: 8 [10240/51005 (20%)]\tLoss: 0.019215\n",
      "Train Epoch: 8 [10880/51005 (21%)]\tLoss: 0.004213\n",
      "Train Epoch: 8 [11520/51005 (23%)]\tLoss: 0.011746\n",
      "Train Epoch: 8 [12160/51005 (24%)]\tLoss: 0.019555\n",
      "Train Epoch: 8 [12800/51005 (25%)]\tLoss: 0.000879\n",
      "Train Epoch: 8 [13440/51005 (26%)]\tLoss: 0.011040\n",
      "Train Epoch: 8 [14080/51005 (28%)]\tLoss: 0.001561\n",
      "Train Epoch: 8 [14720/51005 (29%)]\tLoss: 0.099028\n",
      "Train Epoch: 8 [15360/51005 (30%)]\tLoss: 0.000589\n",
      "Train Epoch: 8 [16000/51005 (31%)]\tLoss: 0.000530\n",
      "Train Epoch: 8 [16640/51005 (33%)]\tLoss: 0.071650\n",
      "Train Epoch: 8 [17280/51005 (34%)]\tLoss: 0.004130\n",
      "Train Epoch: 8 [17920/51005 (35%)]\tLoss: 0.006176\n",
      "Train Epoch: 8 [18560/51005 (36%)]\tLoss: 0.017573\n",
      "Train Epoch: 8 [19200/51005 (38%)]\tLoss: 0.000221\n",
      "Train Epoch: 8 [19840/51005 (39%)]\tLoss: 0.010367\n",
      "Train Epoch: 8 [20480/51005 (40%)]\tLoss: 0.000377\n",
      "Train Epoch: 8 [21120/51005 (41%)]\tLoss: 0.000734\n",
      "Train Epoch: 8 [21760/51005 (43%)]\tLoss: 0.068734\n",
      "Train Epoch: 8 [22400/51005 (44%)]\tLoss: 0.000662\n",
      "Train Epoch: 8 [23040/51005 (45%)]\tLoss: 0.040937\n",
      "Train Epoch: 8 [23680/51005 (46%)]\tLoss: 0.045469\n",
      "Train Epoch: 8 [24320/51005 (48%)]\tLoss: 0.001961\n",
      "Train Epoch: 8 [24960/51005 (49%)]\tLoss: 0.001449\n",
      "Train Epoch: 8 [25600/51005 (50%)]\tLoss: 0.000456\n",
      "Train Epoch: 8 [26240/51005 (51%)]\tLoss: 0.001535\n",
      "Train Epoch: 8 [26880/51005 (53%)]\tLoss: 0.001665\n",
      "Train Epoch: 8 [27520/51005 (54%)]\tLoss: 0.000923\n",
      "Train Epoch: 8 [28160/51005 (55%)]\tLoss: 0.030010\n",
      "Train Epoch: 8 [28800/51005 (56%)]\tLoss: 0.002262\n",
      "Train Epoch: 8 [29440/51005 (58%)]\tLoss: 0.000980\n",
      "Train Epoch: 8 [30080/51005 (59%)]\tLoss: 0.000729\n",
      "Train Epoch: 8 [30720/51005 (60%)]\tLoss: 0.000049\n",
      "Train Epoch: 8 [31360/51005 (61%)]\tLoss: 0.008847\n",
      "Train Epoch: 8 [32000/51005 (63%)]\tLoss: 0.002828\n",
      "Train Epoch: 8 [32640/51005 (64%)]\tLoss: 0.049997\n",
      "Train Epoch: 8 [33280/51005 (65%)]\tLoss: 0.002778\n",
      "Train Epoch: 8 [33920/51005 (66%)]\tLoss: 0.002896\n",
      "Train Epoch: 8 [34560/51005 (68%)]\tLoss: 0.000919\n",
      "Train Epoch: 8 [35200/51005 (69%)]\tLoss: 0.016557\n",
      "Train Epoch: 8 [35840/51005 (70%)]\tLoss: 0.000623\n",
      "Train Epoch: 8 [36480/51005 (72%)]\tLoss: 0.007050\n",
      "Train Epoch: 8 [37120/51005 (73%)]\tLoss: 0.000183\n",
      "Train Epoch: 8 [37760/51005 (74%)]\tLoss: 0.001409\n",
      "Train Epoch: 8 [38400/51005 (75%)]\tLoss: 0.000815\n",
      "Train Epoch: 8 [39040/51005 (77%)]\tLoss: 0.096070\n",
      "Train Epoch: 8 [39680/51005 (78%)]\tLoss: 0.012088\n",
      "Train Epoch: 8 [40320/51005 (79%)]\tLoss: 0.001703\n",
      "Train Epoch: 8 [40960/51005 (80%)]\tLoss: 0.001703\n",
      "Train Epoch: 8 [41600/51005 (82%)]\tLoss: 0.013928\n",
      "Train Epoch: 8 [42240/51005 (83%)]\tLoss: 0.014265\n",
      "Train Epoch: 8 [42880/51005 (84%)]\tLoss: 0.015566\n",
      "Train Epoch: 8 [43520/51005 (85%)]\tLoss: 0.009248\n",
      "Train Epoch: 8 [44160/51005 (87%)]\tLoss: 0.000411\n",
      "Train Epoch: 8 [44800/51005 (88%)]\tLoss: 0.004784\n",
      "Train Epoch: 8 [45440/51005 (89%)]\tLoss: 0.000311\n",
      "Train Epoch: 8 [46080/51005 (90%)]\tLoss: 0.000345\n",
      "Train Epoch: 8 [46720/51005 (92%)]\tLoss: 0.052311\n",
      "Train Epoch: 8 [47360/51005 (93%)]\tLoss: 0.003729\n",
      "Train Epoch: 8 [48000/51005 (94%)]\tLoss: 0.001027\n",
      "Train Epoch: 8 [48640/51005 (95%)]\tLoss: 0.002076\n",
      "Train Epoch: 8 [49280/51005 (97%)]\tLoss: 0.000271\n",
      "Train Epoch: 8 [49920/51005 (98%)]\tLoss: 0.000198\n",
      "Train Epoch: 8 [50560/51005 (99%)]\tLoss: 0.001561\n",
      "\n",
      "Accuracy: 8937/8995 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/51005 (0%)]\tLoss: 0.010206\n",
      "Train Epoch: 9 [640/51005 (1%)]\tLoss: 0.001037\n",
      "Train Epoch: 9 [1280/51005 (3%)]\tLoss: 0.002126\n",
      "Train Epoch: 9 [1920/51005 (4%)]\tLoss: 0.035791\n",
      "Train Epoch: 9 [2560/51005 (5%)]\tLoss: 0.014529\n",
      "Train Epoch: 9 [3200/51005 (6%)]\tLoss: 0.006660\n",
      "Train Epoch: 9 [3840/51005 (8%)]\tLoss: 0.011370\n",
      "Train Epoch: 9 [4480/51005 (9%)]\tLoss: 0.000739\n",
      "Train Epoch: 9 [5120/51005 (10%)]\tLoss: 0.002465\n",
      "Train Epoch: 9 [5760/51005 (11%)]\tLoss: 0.023368\n",
      "Train Epoch: 9 [6400/51005 (13%)]\tLoss: 0.012083\n",
      "Train Epoch: 9 [7040/51005 (14%)]\tLoss: 0.000089\n",
      "Train Epoch: 9 [7680/51005 (15%)]\tLoss: 0.016414\n",
      "Train Epoch: 9 [8320/51005 (16%)]\tLoss: 0.031318\n",
      "Train Epoch: 9 [8960/51005 (18%)]\tLoss: 0.007785\n",
      "Train Epoch: 9 [9600/51005 (19%)]\tLoss: 0.002092\n",
      "Train Epoch: 9 [10240/51005 (20%)]\tLoss: 0.000831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [10880/51005 (21%)]\tLoss: 0.008719\n",
      "Train Epoch: 9 [11520/51005 (23%)]\tLoss: 0.000101\n",
      "Train Epoch: 9 [12160/51005 (24%)]\tLoss: 0.005234\n",
      "Train Epoch: 9 [12800/51005 (25%)]\tLoss: 0.001354\n",
      "Train Epoch: 9 [13440/51005 (26%)]\tLoss: 0.061550\n",
      "Train Epoch: 9 [14080/51005 (28%)]\tLoss: 0.018965\n",
      "Train Epoch: 9 [14720/51005 (29%)]\tLoss: 0.001564\n",
      "Train Epoch: 9 [15360/51005 (30%)]\tLoss: 0.000415\n",
      "Train Epoch: 9 [16000/51005 (31%)]\tLoss: 0.043009\n",
      "Train Epoch: 9 [16640/51005 (33%)]\tLoss: 0.010522\n",
      "Train Epoch: 9 [17280/51005 (34%)]\tLoss: 0.014553\n",
      "Train Epoch: 9 [17920/51005 (35%)]\tLoss: 0.004091\n",
      "Train Epoch: 9 [18560/51005 (36%)]\tLoss: 0.000303\n",
      "Train Epoch: 9 [19200/51005 (38%)]\tLoss: 0.003219\n",
      "Train Epoch: 9 [19840/51005 (39%)]\tLoss: 0.051543\n",
      "Train Epoch: 9 [20480/51005 (40%)]\tLoss: 0.021633\n",
      "Train Epoch: 9 [21120/51005 (41%)]\tLoss: 0.004181\n",
      "Train Epoch: 9 [21760/51005 (43%)]\tLoss: 0.005587\n",
      "Train Epoch: 9 [22400/51005 (44%)]\tLoss: 0.005459\n",
      "Train Epoch: 9 [23040/51005 (45%)]\tLoss: 0.043202\n",
      "Train Epoch: 9 [23680/51005 (46%)]\tLoss: 0.149713\n",
      "Train Epoch: 9 [24320/51005 (48%)]\tLoss: 0.003327\n",
      "Train Epoch: 9 [24960/51005 (49%)]\tLoss: 0.000640\n",
      "Train Epoch: 9 [25600/51005 (50%)]\tLoss: 0.031882\n",
      "Train Epoch: 9 [26240/51005 (51%)]\tLoss: 0.002224\n",
      "Train Epoch: 9 [26880/51005 (53%)]\tLoss: 0.007054\n",
      "Train Epoch: 9 [27520/51005 (54%)]\tLoss: 0.004646\n",
      "Train Epoch: 9 [28160/51005 (55%)]\tLoss: 0.003262\n",
      "Train Epoch: 9 [28800/51005 (56%)]\tLoss: 0.006422\n",
      "Train Epoch: 9 [29440/51005 (58%)]\tLoss: 0.002768\n",
      "Train Epoch: 9 [30080/51005 (59%)]\tLoss: 0.022347\n",
      "Train Epoch: 9 [30720/51005 (60%)]\tLoss: 0.000537\n",
      "Train Epoch: 9 [31360/51005 (61%)]\tLoss: 0.000072\n",
      "Train Epoch: 9 [32000/51005 (63%)]\tLoss: 0.001492\n",
      "Train Epoch: 9 [32640/51005 (64%)]\tLoss: 0.004932\n",
      "Train Epoch: 9 [33280/51005 (65%)]\tLoss: 0.001520\n",
      "Train Epoch: 9 [33920/51005 (66%)]\tLoss: 0.001783\n",
      "Train Epoch: 9 [34560/51005 (68%)]\tLoss: 0.002506\n",
      "Train Epoch: 9 [35200/51005 (69%)]\tLoss: 0.020773\n",
      "Train Epoch: 9 [35840/51005 (70%)]\tLoss: 0.153120\n",
      "Train Epoch: 9 [36480/51005 (72%)]\tLoss: 0.001660\n",
      "Train Epoch: 9 [37120/51005 (73%)]\tLoss: 0.006391\n",
      "Train Epoch: 9 [37760/51005 (74%)]\tLoss: 0.000711\n",
      "Train Epoch: 9 [38400/51005 (75%)]\tLoss: 0.000877\n",
      "Train Epoch: 9 [39040/51005 (77%)]\tLoss: 0.026707\n",
      "Train Epoch: 9 [39680/51005 (78%)]\tLoss: 0.002666\n",
      "Train Epoch: 9 [40320/51005 (79%)]\tLoss: 0.098921\n",
      "Train Epoch: 9 [40960/51005 (80%)]\tLoss: 0.001245\n",
      "Train Epoch: 9 [41600/51005 (82%)]\tLoss: 0.017766\n",
      "Train Epoch: 9 [42240/51005 (83%)]\tLoss: 0.001379\n",
      "Train Epoch: 9 [42880/51005 (84%)]\tLoss: 0.030654\n",
      "Train Epoch: 9 [43520/51005 (85%)]\tLoss: 0.006066\n",
      "Train Epoch: 9 [44160/51005 (87%)]\tLoss: 0.031918\n",
      "Train Epoch: 9 [44800/51005 (88%)]\tLoss: 0.009250\n",
      "Train Epoch: 9 [45440/51005 (89%)]\tLoss: 0.006911\n",
      "Train Epoch: 9 [46080/51005 (90%)]\tLoss: 0.012007\n",
      "Train Epoch: 9 [46720/51005 (92%)]\tLoss: 0.001468\n",
      "Train Epoch: 9 [47360/51005 (93%)]\tLoss: 0.001069\n",
      "Train Epoch: 9 [48000/51005 (94%)]\tLoss: 0.055364\n",
      "Train Epoch: 9 [48640/51005 (95%)]\tLoss: 0.006782\n",
      "Train Epoch: 9 [49280/51005 (97%)]\tLoss: 0.002160\n",
      "Train Epoch: 9 [49920/51005 (98%)]\tLoss: 0.003361\n",
      "Train Epoch: 9 [50560/51005 (99%)]\tLoss: 0.032522\n",
      "\n",
      "Accuracy: 8943/8995 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/51005 (0%)]\tLoss: 0.109837\n",
      "Train Epoch: 10 [640/51005 (1%)]\tLoss: 0.001992\n",
      "Train Epoch: 10 [1280/51005 (3%)]\tLoss: 0.013325\n",
      "Train Epoch: 10 [1920/51005 (4%)]\tLoss: 0.001494\n",
      "Train Epoch: 10 [2560/51005 (5%)]\tLoss: 0.002033\n",
      "Train Epoch: 10 [3200/51005 (6%)]\tLoss: 0.019489\n",
      "Train Epoch: 10 [3840/51005 (8%)]\tLoss: 0.063699\n",
      "Train Epoch: 10 [4480/51005 (9%)]\tLoss: 0.002836\n",
      "Train Epoch: 10 [5120/51005 (10%)]\tLoss: 0.001298\n",
      "Train Epoch: 10 [5760/51005 (11%)]\tLoss: 0.002988\n",
      "Train Epoch: 10 [6400/51005 (13%)]\tLoss: 0.000779\n",
      "Train Epoch: 10 [7040/51005 (14%)]\tLoss: 0.000210\n",
      "Train Epoch: 10 [7680/51005 (15%)]\tLoss: 0.000571\n",
      "Train Epoch: 10 [8320/51005 (16%)]\tLoss: 0.002100\n",
      "Train Epoch: 10 [8960/51005 (18%)]\tLoss: 0.003393\n",
      "Train Epoch: 10 [9600/51005 (19%)]\tLoss: 0.006108\n",
      "Train Epoch: 10 [10240/51005 (20%)]\tLoss: 0.021852\n",
      "Train Epoch: 10 [10880/51005 (21%)]\tLoss: 0.026765\n",
      "Train Epoch: 10 [11520/51005 (23%)]\tLoss: 0.000294\n",
      "Train Epoch: 10 [12160/51005 (24%)]\tLoss: 0.000133\n",
      "Train Epoch: 10 [12800/51005 (25%)]\tLoss: 0.015124\n",
      "Train Epoch: 10 [13440/51005 (26%)]\tLoss: 0.000758\n",
      "Train Epoch: 10 [14080/51005 (28%)]\tLoss: 0.002290\n",
      "Train Epoch: 10 [14720/51005 (29%)]\tLoss: 0.004429\n",
      "Train Epoch: 10 [15360/51005 (30%)]\tLoss: 0.002362\n",
      "Train Epoch: 10 [16000/51005 (31%)]\tLoss: 0.015568\n",
      "Train Epoch: 10 [16640/51005 (33%)]\tLoss: 0.104836\n",
      "Train Epoch: 10 [17280/51005 (34%)]\tLoss: 0.039041\n",
      "Train Epoch: 10 [17920/51005 (35%)]\tLoss: 0.008721\n",
      "Train Epoch: 10 [18560/51005 (36%)]\tLoss: 0.007353\n",
      "Train Epoch: 10 [19200/51005 (38%)]\tLoss: 0.015947\n",
      "Train Epoch: 10 [19840/51005 (39%)]\tLoss: 0.008506\n",
      "Train Epoch: 10 [20480/51005 (40%)]\tLoss: 0.001139\n",
      "Train Epoch: 10 [21120/51005 (41%)]\tLoss: 0.011052\n",
      "Train Epoch: 10 [21760/51005 (43%)]\tLoss: 0.015329\n",
      "Train Epoch: 10 [22400/51005 (44%)]\tLoss: 0.001159\n",
      "Train Epoch: 10 [23040/51005 (45%)]\tLoss: 0.004836\n",
      "Train Epoch: 10 [23680/51005 (46%)]\tLoss: 0.081065\n",
      "Train Epoch: 10 [24320/51005 (48%)]\tLoss: 0.004916\n",
      "Train Epoch: 10 [24960/51005 (49%)]\tLoss: 0.001513\n",
      "Train Epoch: 10 [25600/51005 (50%)]\tLoss: 0.032546\n",
      "Train Epoch: 10 [26240/51005 (51%)]\tLoss: 0.000821\n",
      "Train Epoch: 10 [26880/51005 (53%)]\tLoss: 0.002084\n",
      "Train Epoch: 10 [27520/51005 (54%)]\tLoss: 0.022392\n",
      "Train Epoch: 10 [28160/51005 (55%)]\tLoss: 0.000774\n",
      "Train Epoch: 10 [28800/51005 (56%)]\tLoss: 0.006951\n",
      "Train Epoch: 10 [29440/51005 (58%)]\tLoss: 0.001699\n",
      "Train Epoch: 10 [30080/51005 (59%)]\tLoss: 0.002839\n",
      "Train Epoch: 10 [30720/51005 (60%)]\tLoss: 0.000969\n",
      "Train Epoch: 10 [31360/51005 (61%)]\tLoss: 0.013070\n",
      "Train Epoch: 10 [32000/51005 (63%)]\tLoss: 0.001997\n",
      "Train Epoch: 10 [32640/51005 (64%)]\tLoss: 0.016677\n",
      "Train Epoch: 10 [33280/51005 (65%)]\tLoss: 0.003764\n",
      "Train Epoch: 10 [33920/51005 (66%)]\tLoss: 0.000053\n",
      "Train Epoch: 10 [34560/51005 (68%)]\tLoss: 0.002246\n",
      "Train Epoch: 10 [35200/51005 (69%)]\tLoss: 0.000930\n",
      "Train Epoch: 10 [35840/51005 (70%)]\tLoss: 0.011726\n",
      "Train Epoch: 10 [36480/51005 (72%)]\tLoss: 0.010107\n",
      "Train Epoch: 10 [37120/51005 (73%)]\tLoss: 0.002007\n",
      "Train Epoch: 10 [37760/51005 (74%)]\tLoss: 0.003538\n",
      "Train Epoch: 10 [38400/51005 (75%)]\tLoss: 0.000349\n",
      "Train Epoch: 10 [39040/51005 (77%)]\tLoss: 0.010434\n",
      "Train Epoch: 10 [39680/51005 (78%)]\tLoss: 0.000351\n",
      "Train Epoch: 10 [40320/51005 (79%)]\tLoss: 0.098176\n",
      "Train Epoch: 10 [40960/51005 (80%)]\tLoss: 0.009878\n",
      "Train Epoch: 10 [41600/51005 (82%)]\tLoss: 0.000628\n",
      "Train Epoch: 10 [42240/51005 (83%)]\tLoss: 0.017134\n",
      "Train Epoch: 10 [42880/51005 (84%)]\tLoss: 0.003236\n",
      "Train Epoch: 10 [43520/51005 (85%)]\tLoss: 0.005384\n",
      "Train Epoch: 10 [44160/51005 (87%)]\tLoss: 0.000584\n",
      "Train Epoch: 10 [44800/51005 (88%)]\tLoss: 0.003696\n",
      "Train Epoch: 10 [45440/51005 (89%)]\tLoss: 0.000476\n",
      "Train Epoch: 10 [46080/51005 (90%)]\tLoss: 0.013326\n",
      "Train Epoch: 10 [46720/51005 (92%)]\tLoss: 0.030428\n",
      "Train Epoch: 10 [47360/51005 (93%)]\tLoss: 0.013166\n",
      "Train Epoch: 10 [48000/51005 (94%)]\tLoss: 0.001037\n",
      "Train Epoch: 10 [48640/51005 (95%)]\tLoss: 0.002156\n",
      "Train Epoch: 10 [49280/51005 (97%)]\tLoss: 0.004590\n",
      "Train Epoch: 10 [49920/51005 (98%)]\tLoss: 0.020170\n",
      "Train Epoch: 10 [50560/51005 (99%)]\tLoss: 0.011193\n",
      "\n",
      "Accuracy: 8942/8995 (99%)\n",
      "\n",
      "Train Epoch: 11 [0/51005 (0%)]\tLoss: 0.002194\n",
      "Train Epoch: 11 [640/51005 (1%)]\tLoss: 0.001654\n",
      "Train Epoch: 11 [1280/51005 (3%)]\tLoss: 0.005543\n",
      "Train Epoch: 11 [1920/51005 (4%)]\tLoss: 0.002403\n",
      "Train Epoch: 11 [2560/51005 (5%)]\tLoss: 0.009462\n",
      "Train Epoch: 11 [3200/51005 (6%)]\tLoss: 0.004632\n",
      "Train Epoch: 11 [3840/51005 (8%)]\tLoss: 0.002991\n",
      "Train Epoch: 11 [4480/51005 (9%)]\tLoss: 0.019708\n",
      "Train Epoch: 11 [5120/51005 (10%)]\tLoss: 0.028513\n",
      "Train Epoch: 11 [5760/51005 (11%)]\tLoss: 0.025311\n",
      "Train Epoch: 11 [6400/51005 (13%)]\tLoss: 0.000782\n",
      "Train Epoch: 11 [7040/51005 (14%)]\tLoss: 0.001698\n",
      "Train Epoch: 11 [7680/51005 (15%)]\tLoss: 0.000495\n",
      "Train Epoch: 11 [8320/51005 (16%)]\tLoss: 0.000152\n",
      "Train Epoch: 11 [8960/51005 (18%)]\tLoss: 0.016163\n",
      "Train Epoch: 11 [9600/51005 (19%)]\tLoss: 0.003750\n",
      "Train Epoch: 11 [10240/51005 (20%)]\tLoss: 0.000063\n",
      "Train Epoch: 11 [10880/51005 (21%)]\tLoss: 0.000809\n",
      "Train Epoch: 11 [11520/51005 (23%)]\tLoss: 0.002682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [12160/51005 (24%)]\tLoss: 0.002426\n",
      "Train Epoch: 11 [12800/51005 (25%)]\tLoss: 0.006307\n",
      "Train Epoch: 11 [13440/51005 (26%)]\tLoss: 0.000794\n",
      "Train Epoch: 11 [14080/51005 (28%)]\tLoss: 0.003851\n",
      "Train Epoch: 11 [14720/51005 (29%)]\tLoss: 0.005577\n",
      "Train Epoch: 11 [15360/51005 (30%)]\tLoss: 0.014773\n",
      "Train Epoch: 11 [16000/51005 (31%)]\tLoss: 0.043171\n",
      "Train Epoch: 11 [16640/51005 (33%)]\tLoss: 0.000737\n",
      "Train Epoch: 11 [17280/51005 (34%)]\tLoss: 0.000921\n",
      "Train Epoch: 11 [17920/51005 (35%)]\tLoss: 0.004339\n",
      "Train Epoch: 11 [18560/51005 (36%)]\tLoss: 0.002797\n",
      "Train Epoch: 11 [19200/51005 (38%)]\tLoss: 0.017565\n",
      "Train Epoch: 11 [19840/51005 (39%)]\tLoss: 0.001167\n",
      "Train Epoch: 11 [20480/51005 (40%)]\tLoss: 0.029530\n",
      "Train Epoch: 11 [21120/51005 (41%)]\tLoss: 0.000063\n",
      "Train Epoch: 11 [21760/51005 (43%)]\tLoss: 0.005302\n",
      "Train Epoch: 11 [22400/51005 (44%)]\tLoss: 0.018376\n",
      "Train Epoch: 11 [23040/51005 (45%)]\tLoss: 0.002963\n",
      "Train Epoch: 11 [23680/51005 (46%)]\tLoss: 0.002674\n",
      "Train Epoch: 11 [24320/51005 (48%)]\tLoss: 0.011508\n",
      "Train Epoch: 11 [24960/51005 (49%)]\tLoss: 0.000849\n",
      "Train Epoch: 11 [25600/51005 (50%)]\tLoss: 0.004286\n",
      "Train Epoch: 11 [26240/51005 (51%)]\tLoss: 0.000301\n",
      "Train Epoch: 11 [26880/51005 (53%)]\tLoss: 0.001075\n",
      "Train Epoch: 11 [27520/51005 (54%)]\tLoss: 0.003963\n",
      "Train Epoch: 11 [28160/51005 (55%)]\tLoss: 0.012355\n",
      "Train Epoch: 11 [28800/51005 (56%)]\tLoss: 0.005392\n",
      "Train Epoch: 11 [29440/51005 (58%)]\tLoss: 0.002034\n",
      "Train Epoch: 11 [30080/51005 (59%)]\tLoss: 0.000273\n",
      "Train Epoch: 11 [30720/51005 (60%)]\tLoss: 0.000761\n",
      "Train Epoch: 11 [31360/51005 (61%)]\tLoss: 0.006164\n",
      "Train Epoch: 11 [32000/51005 (63%)]\tLoss: 0.000864\n",
      "Train Epoch: 11 [32640/51005 (64%)]\tLoss: 0.002510\n",
      "Train Epoch: 11 [33280/51005 (65%)]\tLoss: 0.004490\n",
      "Train Epoch: 11 [33920/51005 (66%)]\tLoss: 0.000468\n",
      "Train Epoch: 11 [34560/51005 (68%)]\tLoss: 0.074982\n",
      "Train Epoch: 11 [35200/51005 (69%)]\tLoss: 0.000310\n",
      "Train Epoch: 11 [35840/51005 (70%)]\tLoss: 0.009544\n",
      "Train Epoch: 11 [36480/51005 (72%)]\tLoss: 0.000839\n",
      "Train Epoch: 11 [37120/51005 (73%)]\tLoss: 0.000065\n",
      "Train Epoch: 11 [37760/51005 (74%)]\tLoss: 0.041414\n",
      "Train Epoch: 11 [38400/51005 (75%)]\tLoss: 0.005771\n",
      "Train Epoch: 11 [39040/51005 (77%)]\tLoss: 0.000198\n",
      "Train Epoch: 11 [39680/51005 (78%)]\tLoss: 0.001102\n",
      "Train Epoch: 11 [40320/51005 (79%)]\tLoss: 0.004361\n",
      "Train Epoch: 11 [40960/51005 (80%)]\tLoss: 0.054466\n",
      "Train Epoch: 11 [41600/51005 (82%)]\tLoss: 0.003504\n",
      "Train Epoch: 11 [42240/51005 (83%)]\tLoss: 0.001480\n",
      "Train Epoch: 11 [42880/51005 (84%)]\tLoss: 0.001632\n",
      "Train Epoch: 11 [43520/51005 (85%)]\tLoss: 0.003603\n",
      "Train Epoch: 11 [44160/51005 (87%)]\tLoss: 0.001304\n",
      "Train Epoch: 11 [44800/51005 (88%)]\tLoss: 0.001676\n",
      "Train Epoch: 11 [45440/51005 (89%)]\tLoss: 0.024487\n",
      "Train Epoch: 11 [46080/51005 (90%)]\tLoss: 0.002666\n",
      "Train Epoch: 11 [46720/51005 (92%)]\tLoss: 0.055849\n",
      "Train Epoch: 11 [47360/51005 (93%)]\tLoss: 0.000714\n",
      "Train Epoch: 11 [48000/51005 (94%)]\tLoss: 0.000752\n",
      "Train Epoch: 11 [48640/51005 (95%)]\tLoss: 0.003673\n",
      "Train Epoch: 11 [49280/51005 (97%)]\tLoss: 0.024129\n",
      "Train Epoch: 11 [49920/51005 (98%)]\tLoss: 0.000632\n",
      "Train Epoch: 11 [50560/51005 (99%)]\tLoss: 0.001285\n",
      "\n",
      "Accuracy: 8940/8995 (99%)\n",
      "\n",
      "Train Epoch: 12 [0/51005 (0%)]\tLoss: 0.000828\n",
      "Train Epoch: 12 [640/51005 (1%)]\tLoss: 0.000237\n",
      "Train Epoch: 12 [1280/51005 (3%)]\tLoss: 0.021457\n",
      "Train Epoch: 12 [1920/51005 (4%)]\tLoss: 0.000171\n",
      "Train Epoch: 12 [2560/51005 (5%)]\tLoss: 0.003136\n",
      "Train Epoch: 12 [3200/51005 (6%)]\tLoss: 0.050829\n",
      "Train Epoch: 12 [3840/51005 (8%)]\tLoss: 0.009054\n",
      "Train Epoch: 12 [4480/51005 (9%)]\tLoss: 0.001603\n",
      "Train Epoch: 12 [5120/51005 (10%)]\tLoss: 0.000189\n",
      "Train Epoch: 12 [5760/51005 (11%)]\tLoss: 0.053462\n",
      "Train Epoch: 12 [6400/51005 (13%)]\tLoss: 0.011831\n",
      "Train Epoch: 12 [7040/51005 (14%)]\tLoss: 0.001028\n",
      "Train Epoch: 12 [7680/51005 (15%)]\tLoss: 0.006562\n",
      "Train Epoch: 12 [8320/51005 (16%)]\tLoss: 0.000060\n",
      "Train Epoch: 12 [8960/51005 (18%)]\tLoss: 0.002441\n",
      "Train Epoch: 12 [9600/51005 (19%)]\tLoss: 0.075400\n",
      "Train Epoch: 12 [10240/51005 (20%)]\tLoss: 0.000223\n",
      "Train Epoch: 12 [10880/51005 (21%)]\tLoss: 0.000363\n",
      "Train Epoch: 12 [11520/51005 (23%)]\tLoss: 0.002797\n",
      "Train Epoch: 12 [12160/51005 (24%)]\tLoss: 0.003637\n",
      "Train Epoch: 12 [12800/51005 (25%)]\tLoss: 0.001391\n",
      "Train Epoch: 12 [13440/51005 (26%)]\tLoss: 0.000330\n",
      "Train Epoch: 12 [14080/51005 (28%)]\tLoss: 0.004870\n",
      "Train Epoch: 12 [14720/51005 (29%)]\tLoss: 0.004665\n",
      "Train Epoch: 12 [15360/51005 (30%)]\tLoss: 0.001017\n",
      "Train Epoch: 12 [16000/51005 (31%)]\tLoss: 0.002121\n",
      "Train Epoch: 12 [16640/51005 (33%)]\tLoss: 0.003220\n",
      "Train Epoch: 12 [17280/51005 (34%)]\tLoss: 0.005136\n",
      "Train Epoch: 12 [17920/51005 (35%)]\tLoss: 0.015969\n",
      "Train Epoch: 12 [18560/51005 (36%)]\tLoss: 0.001170\n",
      "Train Epoch: 12 [19200/51005 (38%)]\tLoss: 0.011704\n",
      "Train Epoch: 12 [19840/51005 (39%)]\tLoss: 0.027699\n",
      "Train Epoch: 12 [20480/51005 (40%)]\tLoss: 0.007418\n",
      "Train Epoch: 12 [21120/51005 (41%)]\tLoss: 0.000449\n",
      "Train Epoch: 12 [21760/51005 (43%)]\tLoss: 0.000624\n",
      "Train Epoch: 12 [22400/51005 (44%)]\tLoss: 0.007091\n",
      "Train Epoch: 12 [23040/51005 (45%)]\tLoss: 0.001912\n",
      "Train Epoch: 12 [23680/51005 (46%)]\tLoss: 0.003047\n",
      "Train Epoch: 12 [24320/51005 (48%)]\tLoss: 0.003958\n",
      "Train Epoch: 12 [24960/51005 (49%)]\tLoss: 0.002084\n",
      "Train Epoch: 12 [25600/51005 (50%)]\tLoss: 0.000186\n",
      "Train Epoch: 12 [26240/51005 (51%)]\tLoss: 0.003656\n",
      "Train Epoch: 12 [26880/51005 (53%)]\tLoss: 0.000880\n",
      "Train Epoch: 12 [27520/51005 (54%)]\tLoss: 0.001685\n",
      "Train Epoch: 12 [28160/51005 (55%)]\tLoss: 0.001079\n",
      "Train Epoch: 12 [28800/51005 (56%)]\tLoss: 0.013620\n",
      "Train Epoch: 12 [29440/51005 (58%)]\tLoss: 0.048711\n",
      "Train Epoch: 12 [30080/51005 (59%)]\tLoss: 0.016138\n",
      "Train Epoch: 12 [30720/51005 (60%)]\tLoss: 0.001757\n",
      "Train Epoch: 12 [31360/51005 (61%)]\tLoss: 0.025310\n",
      "Train Epoch: 12 [32000/51005 (63%)]\tLoss: 0.035716\n",
      "Train Epoch: 12 [32640/51005 (64%)]\tLoss: 0.001434\n",
      "Train Epoch: 12 [33280/51005 (65%)]\tLoss: 0.003744\n",
      "Train Epoch: 12 [33920/51005 (66%)]\tLoss: 0.009189\n",
      "Train Epoch: 12 [34560/51005 (68%)]\tLoss: 0.000889\n",
      "Train Epoch: 12 [35200/51005 (69%)]\tLoss: 0.000176\n",
      "Train Epoch: 12 [35840/51005 (70%)]\tLoss: 0.001110\n",
      "Train Epoch: 12 [36480/51005 (72%)]\tLoss: 0.001044\n",
      "Train Epoch: 12 [37120/51005 (73%)]\tLoss: 0.000793\n",
      "Train Epoch: 12 [37760/51005 (74%)]\tLoss: 0.003031\n",
      "Train Epoch: 12 [38400/51005 (75%)]\tLoss: 0.007166\n",
      "Train Epoch: 12 [39040/51005 (77%)]\tLoss: 0.002569\n",
      "Train Epoch: 12 [39680/51005 (78%)]\tLoss: 0.001931\n",
      "Train Epoch: 12 [40320/51005 (79%)]\tLoss: 0.027130\n",
      "Train Epoch: 12 [40960/51005 (80%)]\tLoss: 0.002471\n",
      "Train Epoch: 12 [41600/51005 (82%)]\tLoss: 0.021700\n",
      "Train Epoch: 12 [42240/51005 (83%)]\tLoss: 0.000490\n",
      "Train Epoch: 12 [42880/51005 (84%)]\tLoss: 0.001709\n",
      "Train Epoch: 12 [43520/51005 (85%)]\tLoss: 0.006382\n",
      "Train Epoch: 12 [44160/51005 (87%)]\tLoss: 0.003374\n",
      "Train Epoch: 12 [44800/51005 (88%)]\tLoss: 0.046453\n",
      "Train Epoch: 12 [45440/51005 (89%)]\tLoss: 0.000498\n",
      "Train Epoch: 12 [46080/51005 (90%)]\tLoss: 0.013345\n",
      "Train Epoch: 12 [46720/51005 (92%)]\tLoss: 0.007750\n",
      "Train Epoch: 12 [47360/51005 (93%)]\tLoss: 0.020011\n",
      "Train Epoch: 12 [48000/51005 (94%)]\tLoss: 0.009440\n",
      "Train Epoch: 12 [48640/51005 (95%)]\tLoss: 0.004248\n",
      "Train Epoch: 12 [49280/51005 (97%)]\tLoss: 0.004391\n",
      "Train Epoch: 12 [49920/51005 (98%)]\tLoss: 0.000070\n",
      "Train Epoch: 12 [50560/51005 (99%)]\tLoss: 0.003789\n",
      "\n",
      "Accuracy: 8941/8995 (99%)\n",
      "\n",
      "Train Epoch: 13 [0/51005 (0%)]\tLoss: 0.000963\n",
      "Train Epoch: 13 [640/51005 (1%)]\tLoss: 0.003382\n",
      "Train Epoch: 13 [1280/51005 (3%)]\tLoss: 0.047327\n",
      "Train Epoch: 13 [1920/51005 (4%)]\tLoss: 0.000206\n",
      "Train Epoch: 13 [2560/51005 (5%)]\tLoss: 0.025600\n",
      "Train Epoch: 13 [3200/51005 (6%)]\tLoss: 0.001329\n",
      "Train Epoch: 13 [3840/51005 (8%)]\tLoss: 0.002377\n",
      "Train Epoch: 13 [4480/51005 (9%)]\tLoss: 0.007369\n",
      "Train Epoch: 13 [5120/51005 (10%)]\tLoss: 0.004246\n",
      "Train Epoch: 13 [5760/51005 (11%)]\tLoss: 0.001323\n",
      "Train Epoch: 13 [6400/51005 (13%)]\tLoss: 0.000916\n",
      "Train Epoch: 13 [7040/51005 (14%)]\tLoss: 0.002665\n",
      "Train Epoch: 13 [7680/51005 (15%)]\tLoss: 0.000166\n",
      "Train Epoch: 13 [8320/51005 (16%)]\tLoss: 0.087393\n",
      "Train Epoch: 13 [8960/51005 (18%)]\tLoss: 0.001344\n",
      "Train Epoch: 13 [9600/51005 (19%)]\tLoss: 0.000694\n",
      "Train Epoch: 13 [10240/51005 (20%)]\tLoss: 0.089038\n",
      "Train Epoch: 13 [10880/51005 (21%)]\tLoss: 0.000216\n",
      "Train Epoch: 13 [11520/51005 (23%)]\tLoss: 0.031400\n",
      "Train Epoch: 13 [12160/51005 (24%)]\tLoss: 0.000870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [12800/51005 (25%)]\tLoss: 0.002839\n",
      "Train Epoch: 13 [13440/51005 (26%)]\tLoss: 0.001090\n",
      "Train Epoch: 13 [14080/51005 (28%)]\tLoss: 0.014325\n",
      "Train Epoch: 13 [14720/51005 (29%)]\tLoss: 0.001048\n",
      "Train Epoch: 13 [15360/51005 (30%)]\tLoss: 0.000442\n",
      "Train Epoch: 13 [16000/51005 (31%)]\tLoss: 0.000703\n",
      "Train Epoch: 13 [16640/51005 (33%)]\tLoss: 0.004146\n",
      "Train Epoch: 13 [17280/51005 (34%)]\tLoss: 0.003064\n",
      "Train Epoch: 13 [17920/51005 (35%)]\tLoss: 0.026992\n",
      "Train Epoch: 13 [18560/51005 (36%)]\tLoss: 0.000773\n",
      "Train Epoch: 13 [19200/51005 (38%)]\tLoss: 0.090250\n",
      "Train Epoch: 13 [19840/51005 (39%)]\tLoss: 0.003449\n",
      "Train Epoch: 13 [20480/51005 (40%)]\tLoss: 0.000129\n",
      "Train Epoch: 13 [21120/51005 (41%)]\tLoss: 0.008820\n",
      "Train Epoch: 13 [21760/51005 (43%)]\tLoss: 0.000138\n",
      "Train Epoch: 13 [22400/51005 (44%)]\tLoss: 0.006140\n",
      "Train Epoch: 13 [23040/51005 (45%)]\tLoss: 0.002567\n",
      "Train Epoch: 13 [23680/51005 (46%)]\tLoss: 0.000622\n",
      "Train Epoch: 13 [24320/51005 (48%)]\tLoss: 0.001230\n",
      "Train Epoch: 13 [24960/51005 (49%)]\tLoss: 0.012238\n",
      "Train Epoch: 13 [25600/51005 (50%)]\tLoss: 0.000348\n",
      "Train Epoch: 13 [26240/51005 (51%)]\tLoss: 0.001231\n",
      "Train Epoch: 13 [26880/51005 (53%)]\tLoss: 0.000765\n",
      "Train Epoch: 13 [27520/51005 (54%)]\tLoss: 0.008134\n",
      "Train Epoch: 13 [28160/51005 (55%)]\tLoss: 0.000871\n",
      "Train Epoch: 13 [28800/51005 (56%)]\tLoss: 0.005949\n",
      "Train Epoch: 13 [29440/51005 (58%)]\tLoss: 0.003365\n",
      "Train Epoch: 13 [30080/51005 (59%)]\tLoss: 0.000457\n",
      "Train Epoch: 13 [30720/51005 (60%)]\tLoss: 0.022180\n",
      "Train Epoch: 13 [31360/51005 (61%)]\tLoss: 0.000131\n",
      "Train Epoch: 13 [32000/51005 (63%)]\tLoss: 0.022150\n",
      "Train Epoch: 13 [32640/51005 (64%)]\tLoss: 0.000725\n",
      "Train Epoch: 13 [33280/51005 (65%)]\tLoss: 0.003868\n",
      "Train Epoch: 13 [33920/51005 (66%)]\tLoss: 0.001819\n",
      "Train Epoch: 13 [34560/51005 (68%)]\tLoss: 0.003066\n",
      "Train Epoch: 13 [35200/51005 (69%)]\tLoss: 0.002256\n",
      "Train Epoch: 13 [35840/51005 (70%)]\tLoss: 0.000537\n",
      "Train Epoch: 13 [36480/51005 (72%)]\tLoss: 0.000891\n",
      "Train Epoch: 13 [37120/51005 (73%)]\tLoss: 0.001529\n",
      "Train Epoch: 13 [37760/51005 (74%)]\tLoss: 0.004361\n",
      "Train Epoch: 13 [38400/51005 (75%)]\tLoss: 0.010274\n",
      "Train Epoch: 13 [39040/51005 (77%)]\tLoss: 0.014914\n",
      "Train Epoch: 13 [39680/51005 (78%)]\tLoss: 0.017611\n",
      "Train Epoch: 13 [40320/51005 (79%)]\tLoss: 0.002481\n",
      "Train Epoch: 13 [40960/51005 (80%)]\tLoss: 0.005032\n",
      "Train Epoch: 13 [41600/51005 (82%)]\tLoss: 0.018917\n",
      "Train Epoch: 13 [42240/51005 (83%)]\tLoss: 0.006147\n",
      "Train Epoch: 13 [42880/51005 (84%)]\tLoss: 0.001701\n",
      "Train Epoch: 13 [43520/51005 (85%)]\tLoss: 0.020009\n",
      "Train Epoch: 13 [44160/51005 (87%)]\tLoss: 0.002351\n",
      "Train Epoch: 13 [44800/51005 (88%)]\tLoss: 0.041441\n",
      "Train Epoch: 13 [45440/51005 (89%)]\tLoss: 0.003780\n",
      "Train Epoch: 13 [46080/51005 (90%)]\tLoss: 0.014607\n",
      "Train Epoch: 13 [46720/51005 (92%)]\tLoss: 0.002806\n",
      "Train Epoch: 13 [47360/51005 (93%)]\tLoss: 0.000086\n",
      "Train Epoch: 13 [48000/51005 (94%)]\tLoss: 0.019228\n",
      "Train Epoch: 13 [48640/51005 (95%)]\tLoss: 0.001192\n",
      "Train Epoch: 13 [49280/51005 (97%)]\tLoss: 0.008631\n",
      "Train Epoch: 13 [49920/51005 (98%)]\tLoss: 0.042127\n",
      "Train Epoch: 13 [50560/51005 (99%)]\tLoss: 0.014806\n",
      "\n",
      "Accuracy: 8941/8995 (99%)\n",
      "\n",
      "Train Epoch: 14 [0/51005 (0%)]\tLoss: 0.006223\n",
      "Train Epoch: 14 [640/51005 (1%)]\tLoss: 0.001411\n",
      "Train Epoch: 14 [1280/51005 (3%)]\tLoss: 0.052364\n",
      "Train Epoch: 14 [1920/51005 (4%)]\tLoss: 0.002484\n",
      "Train Epoch: 14 [2560/51005 (5%)]\tLoss: 0.002349\n",
      "Train Epoch: 14 [3200/51005 (6%)]\tLoss: 0.003184\n",
      "Train Epoch: 14 [3840/51005 (8%)]\tLoss: 0.006517\n",
      "Train Epoch: 14 [4480/51005 (9%)]\tLoss: 0.006860\n",
      "Train Epoch: 14 [5120/51005 (10%)]\tLoss: 0.015910\n",
      "Train Epoch: 14 [5760/51005 (11%)]\tLoss: 0.017079\n",
      "Train Epoch: 14 [6400/51005 (13%)]\tLoss: 0.018089\n",
      "Train Epoch: 14 [7040/51005 (14%)]\tLoss: 0.002164\n",
      "Train Epoch: 14 [7680/51005 (15%)]\tLoss: 0.005039\n",
      "Train Epoch: 14 [8320/51005 (16%)]\tLoss: 0.013331\n",
      "Train Epoch: 14 [8960/51005 (18%)]\tLoss: 0.001012\n",
      "Train Epoch: 14 [9600/51005 (19%)]\tLoss: 0.000600\n",
      "Train Epoch: 14 [10240/51005 (20%)]\tLoss: 0.000146\n",
      "Train Epoch: 14 [10880/51005 (21%)]\tLoss: 0.001914\n",
      "Train Epoch: 14 [11520/51005 (23%)]\tLoss: 0.004922\n",
      "Train Epoch: 14 [12160/51005 (24%)]\tLoss: 0.014879\n",
      "Train Epoch: 14 [12800/51005 (25%)]\tLoss: 0.000734\n",
      "Train Epoch: 14 [13440/51005 (26%)]\tLoss: 0.000611\n",
      "Train Epoch: 14 [14080/51005 (28%)]\tLoss: 0.146962\n",
      "Train Epoch: 14 [14720/51005 (29%)]\tLoss: 0.002823\n",
      "Train Epoch: 14 [15360/51005 (30%)]\tLoss: 0.011585\n",
      "Train Epoch: 14 [16000/51005 (31%)]\tLoss: 0.012988\n",
      "Train Epoch: 14 [16640/51005 (33%)]\tLoss: 0.011742\n",
      "Train Epoch: 14 [17280/51005 (34%)]\tLoss: 0.002225\n",
      "Train Epoch: 14 [17920/51005 (35%)]\tLoss: 0.002378\n",
      "Train Epoch: 14 [18560/51005 (36%)]\tLoss: 0.004160\n",
      "Train Epoch: 14 [19200/51005 (38%)]\tLoss: 0.000620\n",
      "Train Epoch: 14 [19840/51005 (39%)]\tLoss: 0.032328\n",
      "Train Epoch: 14 [20480/51005 (40%)]\tLoss: 0.000229\n",
      "Train Epoch: 14 [21120/51005 (41%)]\tLoss: 0.003661\n",
      "Train Epoch: 14 [21760/51005 (43%)]\tLoss: 0.002027\n",
      "Train Epoch: 14 [22400/51005 (44%)]\tLoss: 0.000134\n",
      "Train Epoch: 14 [23040/51005 (45%)]\tLoss: 0.043977\n",
      "Train Epoch: 14 [23680/51005 (46%)]\tLoss: 0.000641\n",
      "Train Epoch: 14 [24320/51005 (48%)]\tLoss: 0.000240\n",
      "Train Epoch: 14 [24960/51005 (49%)]\tLoss: 0.002147\n",
      "Train Epoch: 14 [25600/51005 (50%)]\tLoss: 0.003250\n",
      "Train Epoch: 14 [26240/51005 (51%)]\tLoss: 0.001429\n",
      "Train Epoch: 14 [26880/51005 (53%)]\tLoss: 0.003769\n",
      "Train Epoch: 14 [27520/51005 (54%)]\tLoss: 0.001292\n",
      "Train Epoch: 14 [28160/51005 (55%)]\tLoss: 0.000264\n",
      "Train Epoch: 14 [28800/51005 (56%)]\tLoss: 0.000772\n",
      "Train Epoch: 14 [29440/51005 (58%)]\tLoss: 0.000310\n",
      "Train Epoch: 14 [30080/51005 (59%)]\tLoss: 0.002255\n",
      "Train Epoch: 14 [30720/51005 (60%)]\tLoss: 0.000174\n",
      "Train Epoch: 14 [31360/51005 (61%)]\tLoss: 0.001255\n",
      "Train Epoch: 14 [32000/51005 (63%)]\tLoss: 0.002152\n",
      "Train Epoch: 14 [32640/51005 (64%)]\tLoss: 0.019469\n",
      "Train Epoch: 14 [33280/51005 (65%)]\tLoss: 0.000895\n",
      "Train Epoch: 14 [33920/51005 (66%)]\tLoss: 0.003584\n",
      "Train Epoch: 14 [34560/51005 (68%)]\tLoss: 0.005161\n",
      "Train Epoch: 14 [35200/51005 (69%)]\tLoss: 0.000452\n",
      "Train Epoch: 14 [35840/51005 (70%)]\tLoss: 0.000226\n",
      "Train Epoch: 14 [36480/51005 (72%)]\tLoss: 0.055588\n",
      "Train Epoch: 14 [37120/51005 (73%)]\tLoss: 0.031030\n",
      "Train Epoch: 14 [37760/51005 (74%)]\tLoss: 0.000319\n",
      "Train Epoch: 14 [38400/51005 (75%)]\tLoss: 0.000297\n",
      "Train Epoch: 14 [39040/51005 (77%)]\tLoss: 0.022945\n",
      "Train Epoch: 14 [39680/51005 (78%)]\tLoss: 0.000869\n",
      "Train Epoch: 14 [40320/51005 (79%)]\tLoss: 0.000577\n",
      "Train Epoch: 14 [40960/51005 (80%)]\tLoss: 0.001205\n",
      "Train Epoch: 14 [41600/51005 (82%)]\tLoss: 0.000218\n",
      "Train Epoch: 14 [42240/51005 (83%)]\tLoss: 0.071173\n",
      "Train Epoch: 14 [42880/51005 (84%)]\tLoss: 0.000631\n",
      "Train Epoch: 14 [43520/51005 (85%)]\tLoss: 0.000717\n",
      "Train Epoch: 14 [44160/51005 (87%)]\tLoss: 0.000717\n",
      "Train Epoch: 14 [44800/51005 (88%)]\tLoss: 0.011989\n",
      "Train Epoch: 14 [45440/51005 (89%)]\tLoss: 0.002886\n",
      "Train Epoch: 14 [46080/51005 (90%)]\tLoss: 0.003752\n",
      "Train Epoch: 14 [46720/51005 (92%)]\tLoss: 0.001033\n",
      "Train Epoch: 14 [47360/51005 (93%)]\tLoss: 0.000088\n",
      "Train Epoch: 14 [48000/51005 (94%)]\tLoss: 0.014426\n",
      "Train Epoch: 14 [48640/51005 (95%)]\tLoss: 0.003048\n",
      "Train Epoch: 14 [49280/51005 (97%)]\tLoss: 0.000250\n",
      "Train Epoch: 14 [49920/51005 (98%)]\tLoss: 0.000081\n",
      "Train Epoch: 14 [50560/51005 (99%)]\tLoss: 0.009760\n",
      "\n",
      "Accuracy: 8940/8995 (99%)\n",
      "\n",
      "Validation Set:\n",
      "\n",
      "Accuracy: 8940/8995 (99%)\n",
      "\n",
      "Training Set:\n",
      "\n",
      "Accuracy: 50927/51005 (100%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    '''\n",
    "    Build the best MNIST classifier.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(3,3), stride=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, 1)\n",
    "        self.norm = nn.BatchNorm2d(64)\n",
    "        self.dropout1 = nn.Dropout2d(0.15)\n",
    "        self.dropout2 = nn.Dropout2d(0.15)\n",
    "        self.fc1 = nn.Linear(1600, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "    \n",
    "def train(model, train_loader, optimizer, epoch):\n",
    "    '''\n",
    "    This is your training function. When you call this function, the model is\n",
    "    trained for 1 epoch.\n",
    "    '''\n",
    "    model.train()   # Set the model to training mode\n",
    "    losses = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()               # Clear the gradient\n",
    "        output = model(data)                # Make predictions\n",
    "        loss = F.nll_loss(output, target)   # Compute loss\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()                     # Gradient computation\n",
    "        optimizer.step()                    # Perform a single optimization step\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.sampler),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))     \n",
    "    return np.average(losses)\n",
    "\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()  \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_num = 0\n",
    "    with torch.no_grad():  \n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  \n",
    "            pred = output.argmax(dim=1, keepdim=True) \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            test_num += len(data)\n",
    "\n",
    "    test_loss /= test_num\n",
    "    print('\\nAccuracy: {}/{} ({:.0f}%)\\n'.format( correct, test_num, 100. * correct / test_num))\n",
    "    return test_loss\n",
    "    \n",
    "model = Net()\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "epochs = 14\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss.append(train(model, train_loader, optimizer, epoch))\n",
    "    test_loss.append(test(model, val_loader))\n",
    "    scheduler.step()  \n",
    "\n",
    "print(\"Validation Set:\")\n",
    "test(model, val_loader)\n",
    "print(\"Training Set:\")\n",
    "test(model, train_loader)\n",
    "\n",
    "torch.save(model.state_dict(), \"best_MNIST_Net.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Loss as a Function of Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(10, 10))\n",
    "plt.plot(range(1, epochs+1), train_loss, label=\"Training\")\n",
    "plt.plot(range(1, epochs+1), test_loss, label=\"Validation\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "fig.suptitle(\"TRAINING AND VALIDATION LOSS BY EPOCH\")\n",
    "plt.legend()\n",
    "plt.savefig(\"train_and_valid_loss_by_epoch.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
